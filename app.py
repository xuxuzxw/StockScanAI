# quant_project/app_v3.py
import streamlit as st
import pandas as pd
import numpy as np
import subprocess
import sys
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from sqlalchemy import text

# å¯¼å…¥æ‰€æœ‰é¡¹ç›®æ¨¡å—
import config
import data
import intelligence
import quant_engine

# --- V2.1 UI/UX ä¼˜åŒ–ï¼šå®šä¹‰å…¨å±€è‹±ä¸­è¡¨å¤´ç¿»è¯‘å­—å…¸ (ç™½é‡‘ç‰ˆ) ---
COLUMN_MAPPING = {
    # é€šç”¨
    'ts_code': 'è‚¡ç¥¨ä»£ç ', 'name': 'è‚¡ç¥¨åç§°', 'industry': 'æ‰€å±è¡Œä¸š', 'ann_date': 'å…¬å‘Šæ—¥æœŸ',
    'end_date': 'æŠ¥å‘ŠæœŸ', 'trade_date': 'äº¤æ˜“æ—¥æœŸ', 'close': 'æ”¶ç›˜ä»·', 'price': 'æˆäº¤ä»·æ ¼',
    'update_flag': 'æ›´æ–°æ ‡è¯†', 'f_ann_date': 'é¦–æ¬¡å…¬å‘Šæ—¥',

    # æ’åä¸å› å­
    'ç»¼åˆå¾—åˆ†': 'ç»¼åˆå¾—åˆ†', 'è¡Œä¸šç»¼åˆå¾—åˆ†': 'è¡Œä¸šç»¼åˆå¾—åˆ†',

    # ç­¹ç ç±»
    'holder_name': 'è‚¡ä¸œåç§°', 'holder_type': 'è‚¡ä¸œç±»å‹', 'hold_amount': 'æŒæœ‰æ•°é‡(è‚¡)',
    'hold_ratio': 'æŒè‚¡æ¯”ä¾‹(%)', 'hold_float_ratio': 'å æµé€šè‚¡æ¯”ä¾‹(%)', 'hold_change': 'å˜åŠ¨æ•°é‡(è‚¡)',
    'in_de': 'å¢å‡', 'change_ratio': 'å˜åŠ¨æ¯”ä¾‹(%)', 'avg_price': 'å‡ä»·', 'proc': 'è¿›åº¦',
    'vol': 'æˆäº¤é‡(æ‰‹)', 'amount': 'æˆäº¤é¢(åƒå…ƒ)', 'high_limit': 'å›è´­æœ€é«˜ä»·', 'low_limit': 'å›è´­æœ€ä½ä»·',
    'buyer': 'ä¹°æ–¹', 'seller': 'å–æ–¹', 'net_amount': 'å‡€ä¹°å…¥é¢(ä¸‡å…ƒ)', 'reason': 'ä¸Šæ¦œåŸå› ',

    # è´¢åŠ¡ç±» - é€šç”¨
    'report_type': 'æŠ¥å‘Šç±»å‹', 'comp_type': 'å…¬å¸ç±»å‹', 'end_type': 'æŠ¥å‘ŠæœŸç±»å‹',
    'revenue': 'è¥ä¸šæ”¶å…¥', 'operate_profit': 'è¥ä¸šåˆ©æ¶¦', 'total_profit': 'åˆ©æ¶¦æ€»é¢',
    'n_income': 'å‡€åˆ©æ¶¦', 'total_assets': 'æ€»èµ„äº§', 'total_liab': 'æ€»è´Ÿå€º',
    'total_hldr_eqy_exc_min_int': 'å½’æ¯è‚¡ä¸œæƒç›Š', 'total_hldr_eqy_inc_min_int': 'è‚¡ä¸œæƒç›Šåˆè®¡',
    'basic_eps': 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'diluted_eps': 'ç¨€é‡Šæ¯è‚¡æ”¶ç›Š', 'diluted_roe': 'ç¨€é‡ŠROE(%)',
    'bps': 'æ¯è‚¡å‡€èµ„äº§', 'yoy_op': 'è¥ä¸šåˆ©æ¶¦åŒæ¯”å¢é•¿(%)', 'yoy_gr': 'è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿(%)',
    'yoy_net_profit': 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿(%)',

    # è´¢åŠ¡ç±» - ä¸šç»©é¢„å‘Š/å¿«æŠ¥
    'type': 'é¢„å‘Šç±»å‹', 'p_change_min': 'ä¸šç»©å˜åŠ¨(æœ€å°%)', 'p_change_max': 'ä¸šç»©å˜åŠ¨(æœ€å¤§%)',
    'net_profit_min': 'å‡€åˆ©æ¶¦(æœ€å°)', 'net_profit_max': 'å‡€åˆ©æ¶¦(æœ€å¤§)',
    'last_parent_net': 'ä¸Šå¹´åŒæœŸå½’æ¯å‡€åˆ©æ¶¦', 'first_ann_date': 'é¦–æ¬¡å…¬å‘Šæ—¥',
    'summary': 'ä¸šç»©ç®€è¿°', 'change_reason': 'å˜åŠ¨åŸå› ', 'perf_summary': 'ä¸šç»©æ‘˜è¦',

    # è´¢åŠ¡ç±» - åˆ†çº¢é€è‚¡
    'div_proc': 'åˆ†çº¢æ–¹æ¡ˆ', 'stk_div': 'é€è‚¡(è‚¡)', 'cash_div_tax': 'ç°é‡‘åˆ†çº¢(å…ƒ)',

    # è´¢åŠ¡ç±» - åˆ©æ¶¦è¡¨
    'total_revenue': 'è¥ä¸šæ€»æ”¶å…¥', 'int_income': 'åˆ©æ¯æ”¶å…¥', 'prem_earned': 'å·²èµšä¿è´¹', 'comm_income': 'æ‰‹ç»­è´¹åŠä½£é‡‘æ”¶å…¥',
    'n_commis_income': 'æ‰‹ç»­è´¹åŠä½£é‡‘å‡€æ”¶å…¥', 'n_oth_income': 'å…¶ä»–ç»è¥å‡€æ”¶ç›Š', 'n_oth_b_income': 'å…¶ä»–ä¸šåŠ¡å‡€æ”¶ç›Š',
    'prem_income': 'ä¿é™©ä¸šåŠ¡æ”¶å…¥', 'out_prem': 'åˆ†å‡ºä¿è´¹', 'une_prem_reser': 'æå–æœªåˆ°æœŸè´£ä»»å‡†å¤‡é‡‘',
    'reins_income': 'åˆ†ä¿è´¹æ”¶å…¥', 'n_sec_tb_income': 'ä»£ç†ä¹°å–è¯åˆ¸ä¸šåŠ¡å‡€æ”¶å…¥', 'n_sec_uw_income': 'è¯åˆ¸æ‰¿é”€ä¸šåŠ¡å‡€æ”¶å…¥',
    'n_asset_mg_income': 'å—æ‰˜å®¢æˆ·èµ„äº§ç®¡ç†ä¸šåŠ¡å‡€æ”¶å…¥', 'oth_b_income': 'å…¶ä»–ä¸šåŠ¡æ”¶å…¥', 'fv_value_chg_gain': 'å…¬å…ä»·å€¼å˜åŠ¨æ”¶ç›Š',
    'invest_income': 'æŠ•èµ„æ”¶ç›Š', 'ass_invest_income': 'å¯¹è”è¥å’Œåˆè¥ä¼ä¸šçš„æŠ•èµ„æ”¶ç›Š', 'forex_gain': 'æ±‡å…‘æ”¶ç›Š',
    'total_cogs': 'è¥ä¸šæ€»æˆæœ¬', 'oper_cost': 'è¥ä¸šæˆæœ¬', 'int_exp': 'åˆ©æ¯æ”¯å‡º', 'comm_exp': 'æ‰‹ç»­è´¹åŠä½£é‡‘æ”¯å‡º',
    'biz_tax_surchg': 'è¥ä¸šç¨é‡‘åŠé™„åŠ ', 'sell_exp': 'é”€å”®è´¹ç”¨', 'admin_exp': 'ç®¡ç†è´¹ç”¨', 'fin_exp': 'è´¢åŠ¡è´¹ç”¨',
    'assets_impair_loss': 'èµ„äº§å‡å€¼æŸå¤±', 'prem_refund': 'é€€ä¿é‡‘', 'compens_payout': 'èµ”ä»˜æ”¯å‡ºå‡€é¢', 'compens_payout_refu': 'æ‘Šå›èµ”ä»˜æ”¯å‡º',
    'reser_insur_liab': 'æå–ä¿é™©è´£ä»»å‡†å¤‡é‡‘å‡€é¢', 'insur_reser_refu': 'æ‘Šå›ä¿é™©è´£ä»»å‡†å¤‡é‡‘', 'reins_exp': 'åˆ†ä¿è´¹ç”¨', 'reins_cost_refund': 'æ‘Šå›åˆ†ä¿è´¹ç”¨',
    'oper_exp': 'è¥ä¸šæ”¯å‡º', 'other_bus_cost': 'å…¶ä»–ä¸šåŠ¡æˆæœ¬', 'non_oper_income': 'è¥ä¸šå¤–æ”¶å…¥', 'non_oper_exp': 'è¥ä¸šå¤–æ”¯å‡º',
    'nca_disploss': 'éæµåŠ¨èµ„äº§å¤„ç½®æŸå¤±', 'income_tax': 'æ‰€å¾—ç¨è´¹ç”¨', 'n_income_attr_p': 'å½’å±äºæ¯å…¬å¸æ‰€æœ‰è€…çš„å‡€åˆ©æ¶¦',
    'minority_gain': 'å°‘æ•°è‚¡ä¸œæŸç›Š', 'oth_compr_income': 'å…¶ä»–ç»¼åˆæ”¶ç›Š', 't_compr_income': 'ç»¼åˆæ”¶ç›Šæ€»é¢',
    'compr_inc_attr_p': 'å½’æ¯ç»¼åˆæ”¶ç›Šæ€»é¢', 'compr_inc_attr_m_s': 'å½’å±å°‘æ•°è‚¡ä¸œç»¼åˆæ”¶ç›Šæ€»é¢',
    'ebit': 'æ¯ç¨å‰åˆ©æ¶¦', 'ebitda': 'æ¯ç¨æŠ˜æ—§æ‘Šé”€å‰åˆ©æ¶¦', 'insurance_exp': 'ä¿é™©åˆåŒå‡†å¤‡é‡‘', 'undist_profit': 'æœªåˆ†é…åˆ©æ¶¦',
    'distable_profit': 'å¯åˆ†é…åˆ©æ¶¦', 'rd_exp': 'ç ”å‘è´¹ç”¨', 'fin_exp_int_exp': 'è´¢åŠ¡è´¹ç”¨:åˆ©æ¯è´¹ç”¨', 'fin_exp_int_inc': 'è´¢åŠ¡è´¹ç”¨:åˆ©æ¯æ”¶å…¥',
    'div_payt': 'åº”ä»˜è‚¡åˆ©', 'transfer_surplus_rese': 'ç›ˆä½™å…¬ç§¯è½¬å…¥', 'transfer_housing_imprest': 'ä½æˆ¿å‘¨è½¬é‡‘è½¬å…¥',
    'transfer_oth': 'å…¶ä»–è½¬å…¥', 'adj_lossgain': 'è°ƒæ•´æŸç›Š', 'withdra_legal_surplus': 'æå–æ³•å®šç›ˆä½™å…¬ç§¯',
    'withdra_legal_pubfund': 'æå–æ³•å®šå…¬ç›Šé‡‘', 'withdra_biz_devfund': 'æå–ä¼ä¸šå‘å±•åŸºé‡‘', 'withdra_rese_fund': 'æå–å‚¨å¤‡åŸºé‡‘',
    'withdra_oth_ersu': 'æå–å…¶ä»–ç›ˆä½™å…¬ç§¯', 'workers_welfare': 'èŒå·¥å¥–é‡‘ç¦åˆ©', 'distr_profit_shrhder': 'åˆ†é…ç»™è‚¡ä¸œçš„åˆ©æ¶¦',
    'prfshare_payable_dvd': 'åº”ä»˜ä¼˜å…ˆè‚¡è‚¡åˆ©', 'comshare_payable_dvd': 'åº”ä»˜æ™®é€šè‚¡è‚¡åˆ©', 'capit_comstock_div': 'è½¬ä½œè‚¡æœ¬çš„æ™®é€šè‚¡è‚¡åˆ©',
    'continued_net_profit': 'æŒç»­ç»è¥å‡€åˆ©æ¶¦',

    # è´¢åŠ¡ç±» - èµ„äº§è´Ÿå€ºè¡¨
    'total_share': 'æ€»è‚¡æœ¬', 'cap_rese': 'èµ„æœ¬å…¬ç§¯é‡‘', 'surplus_rese': 'ç›ˆä½™å…¬ç§¯é‡‘', 'special_rese': 'ä¸“é¡¹å‚¨å¤‡',
    'money_cap': 'è´§å¸èµ„é‡‘', 'trad_asset': 'äº¤æ˜“æ€§é‡‘èèµ„äº§', 'notes_receiv': 'åº”æ”¶ç¥¨æ®', 'accounts_receiv': 'åº”æ”¶è´¦æ¬¾',
    'oth_receiv': 'å…¶ä»–åº”æ”¶æ¬¾', 'prepayment': 'é¢„ä»˜æ¬¾é¡¹', 'div_receiv': 'åº”æ”¶è‚¡åˆ©', 'int_receiv': 'åº”æ”¶åˆ©æ¯',
    'inventories': 'å­˜è´§', 'amor_exp': 'é•¿æœŸå¾…æ‘Šè´¹ç”¨', 'nca_within_1y': 'ä¸€å¹´å†…åˆ°æœŸçš„éæµåŠ¨èµ„äº§', 'sett_rsrv': 'ç»“ç®—å¤‡ä»˜é‡‘',
    'loanto_oth_bank_fi': 'æ‹†å‡ºèµ„é‡‘', 'premium_receiv': 'åº”æ”¶ä¿è´¹', 'reinsur_receiv': 'åº”æ”¶åˆ†ä¿è´¦æ¬¾',
    'reinsur_res_receiv': 'åº”æ”¶åˆ†ä¿åˆåŒå‡†å¤‡é‡‘', 'pur_resale_fa': 'ä¹°å…¥è¿”å”®é‡‘èèµ„äº§', 'oth_cur_assets': 'å…¶ä»–æµåŠ¨èµ„äº§',
    'total_cur_assets': 'æµåŠ¨èµ„äº§åˆè®¡', 'fa_avail_for_sale': 'å¯ä¾›å‡ºå”®é‡‘èèµ„äº§', 'htm_invest': 'æŒæœ‰è‡³åˆ°æœŸæŠ•èµ„',
    'lt_eqt_invest': 'é•¿æœŸè‚¡æƒæŠ•èµ„', 'invest_real_estate': 'æŠ•èµ„æ€§æˆ¿åœ°äº§', 'time_deposits': 'å®šæœŸå­˜æ¬¾',
    'oth_assets': 'å…¶ä»–èµ„äº§', 'lt_rec': 'é•¿æœŸåº”æ”¶æ¬¾', 'fix_assets': 'å›ºå®šèµ„äº§', 'cip': 'åœ¨å»ºå·¥ç¨‹',
    'const_materials': 'å·¥ç¨‹ç‰©èµ„', 'fixed_assets_disp': 'å›ºå®šèµ„äº§æ¸…ç†', 'produc_bio_assets': 'ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§',
    'oil_and_gas_assets': 'æ²¹æ°”èµ„äº§', 'intan_assets': 'æ— å½¢èµ„äº§', 'r_and_d': 'ç ”å‘æ”¯å‡º', 'goodwill': 'å•†èª‰',
    'lt_amor_exp': 'é•¿æœŸå¾…æ‘Šè´¹ç”¨', 'defer_tax_assets': 'é€’å»¶æ‰€å¾—ç¨èµ„äº§', 'decr_in_disbur': 'å‘æ”¾è´·æ¬¾åŠå«æ¬¾',
    'oth_nca': 'å…¶ä»–éæµåŠ¨èµ„äº§', 'total_nca': 'éæµåŠ¨èµ„äº§åˆè®¡', 'cash_reser_cb': 'å­˜æ”¾ä¸­å¤®é“¶è¡Œæ¬¾é¡¹',
    'depos_in_oth_bfi': 'å­˜æ”¾åŒä¸šæ¬¾é¡¹', 'prec_metals': 'è´µé‡‘å±', 'deriv_assets': 'è¡ç”Ÿé‡‘èèµ„äº§',
    'rr_reins_une_prem': 'åº”æ”¶åˆ†ä¿æœªåˆ°æœŸè´£ä»»å‡†å¤‡é‡‘', 'rr_reins_outstd_cla': 'åº”æ”¶åˆ†ä¿æœªå†³èµ”æ¬¾å‡†å¤‡é‡‘',
    'rr_reins_lins_liab': 'åº”æ”¶åˆ†ä¿å¯¿é™©è´£ä»»å‡†å¤‡é‡‘', 'rr_reins_lthins_liab': 'åº”æ”¶åˆ†ä¿é•¿æœŸå¥åº·é™©è´£ä»»å‡†å¤‡é‡‘',
    'refund_depos': 'å­˜å‡ºä¿è¯é‡‘', 'ph_pledge_loans': 'ä¿æˆ·è´¨æŠ¼è´·æ¬¾', 'refund_cap_depos': 'å­˜å‡ºèµ„æœ¬ä¿è¯é‡‘',
    'indep_acct_assets': 'ç‹¬ç«‹è´¦æˆ·èµ„äº§', 'client_depos': 'å…¶ä¸­:å®¢æˆ·èµ„é‡‘å­˜æ¬¾', 'client_prov': 'å…¶ä¸­:å®¢æˆ·å¤‡ä»˜é‡‘',
    'transac_seat_fee': 'äº¤æ˜“å¸­ä½è´¹', 'invest_as_receiv': 'åº”æ”¶æ¬¾é¡¹ç±»æŠ•èµ„', 'st_borr': 'çŸ­æœŸå€Ÿæ¬¾',
    'lt_borr': 'é•¿æœŸå€Ÿæ¬¾', 'cb_borr': 'å‘ä¸­å¤®é“¶è¡Œå€Ÿæ¬¾', 'depos_ib_deposits': 'åŒä¸šåŠå…¶ä»–é‡‘èæœºæ„å­˜æ”¾æ¬¾é¡¹',
    'loan_oth_bank': 'æ‹†å…¥èµ„é‡‘', 'trading_fl': 'äº¤æ˜“æ€§é‡‘èè´Ÿå€º', 'notes_payable': 'åº”ä»˜ç¥¨æ®',
    'acct_payable': 'åº”ä»˜è´¦æ¬¾', 'adv_receipts': 'é¢„æ”¶æ¬¾é¡¹', 'sold_for_repur_fa': 'å–å‡ºå›è´­é‡‘èèµ„äº§æ¬¾',
    'comm_payable': 'åº”ä»˜æ‰‹ç»­è´¹åŠä½£é‡‘', 'payroll_payable': 'åº”ä»˜èŒå·¥è–ªé…¬', 'taxes_payable': 'åº”äº¤ç¨è´¹',
    'int_payable': 'åº”ä»˜åˆ©æ¯', 'div_payable': 'åº”ä»˜è‚¡åˆ©', 'oth_payable': 'å…¶ä»–åº”ä»˜æ¬¾', 'acc_exp': 'é¢„æè´¹ç”¨',
    'deferred_inc': 'é€’å»¶æ”¶ç›Š', 'st_bonds_payable': 'åº”ä»˜çŸ­æœŸå€ºåˆ¸', 'payable_to_reinsurer': 'åº”ä»˜åˆ†ä¿è´¦æ¬¾',
    'rsrv_insur_cont': 'ä¿é™©åˆåŒå‡†å¤‡é‡‘', 'acting_trading_sec': 'ä»£ç†ä¹°å–è¯åˆ¸æ¬¾', 'acting_uw_sec': 'ä»£ç†æ‰¿é”€è¯åˆ¸æ¬¾',
    'non_cur_liab_due_1y': 'ä¸€å¹´å†…åˆ°æœŸçš„éæµåŠ¨è´Ÿå€º', 'oth_cur_liab': 'å…¶ä»–æµåŠ¨è´Ÿå€º', 'total_cur_liab': 'æµåŠ¨è´Ÿå€ºåˆè®¡',
    'bond_payable': 'åº”ä»˜å€ºåˆ¸', 'lt_payable': 'é•¿æœŸåº”ä»˜æ¬¾', 'specific_payables': 'ä¸“é¡¹åº”ä»˜æ¬¾',
    'estimated_liab': 'é¢„è®¡è´Ÿå€º', 'defer_tax_liab': 'é€’å»¶æ‰€å¾—ç¨è´Ÿå€º', 'defer_inc_non_cur_liab': 'éæµåŠ¨è´Ÿå€º:é€’å»¶æ”¶ç›Š',
    'oth_ncl': 'å…¶ä»–éæµåŠ¨è´Ÿå€º', 'total_ncl': 'éæµåŠ¨è´Ÿå€ºåˆè®¡', 'depos_oth_bfi': 'åŒä¸šåŠå…¶ä»–é‡‘èæœºæ„å­˜æ”¾æ¬¾é¡¹',
    'deriv_liab': 'è¡ç”Ÿé‡‘èè´Ÿå€º', 'depos': 'å¸æ”¶å­˜æ¬¾', 'agency_bus_liab': 'ä»£ç†ä¸šåŠ¡è´Ÿå€º', 'oth_liab': 'å…¶ä»–è´Ÿå€º',
    'prem_receiv_adva': 'é¢„æ”¶ä¿è´¹', 'depos_received': 'å­˜å…¥ä¿è¯é‡‘', 'ph_invest': 'ä¿æˆ·å‚¨é‡‘åŠæŠ•èµ„æ¬¾',
    'reser_une_prem': 'æœªåˆ°æœŸè´£ä»»å‡†å¤‡é‡‘', 'reser_outstd_claims': 'æœªå†³èµ”æ¬¾å‡†å¤‡é‡‘', 'reser_lins_liab': 'å¯¿é™©è´£ä»»å‡†å¤‡é‡‘',
    'reser_lthins_liab': 'é•¿æœŸå¥åº·é™©è´£ä»»å‡†å¤‡é‡‘', 'indept_acc_liab': 'ç‹¬ç«‹è´¦æˆ·è´Ÿå€º', 'pledge_borr': 'è´¨æŠ¼å€Ÿæ¬¾',
    'indem_payable': 'åº”ä»˜èµ”ä»˜æ¬¾', 'policy_div_payable': 'åº”ä»˜ä¿å•çº¢åˆ©', 'treasury_share': 'åº“å­˜è‚¡',
    'ordin_risk_reser': 'ä¸€èˆ¬é£é™©å‡†å¤‡', 'forex_differ': 'å¤–å¸æŠ¥è¡¨æŠ˜ç®—å·®é¢', 'invest_loss_unconf': 'æœªç¡®è®¤çš„æŠ•èµ„æŸå¤±',
    'minority_int': 'å°‘æ•°è‚¡ä¸œæƒç›Š', 'total_hldr_eqy_inc_min_int': 'è‚¡ä¸œæƒç›Šåˆè®¡',
    'total_liab_hldr_eqy': 'è´Ÿå€ºå’Œè‚¡ä¸œæƒç›Šæ€»è®¡', 'lt_payroll_payable': 'é•¿æœŸåº”ä»˜èŒå·¥è–ªé…¬', 'oth_comp_income': 'å…¶ä»–ç»¼åˆæ”¶ç›Š',
    'oth_eqt_tools': 'å…¶ä»–æƒç›Šå·¥å…·', 'oth_eqt_tools_p_shr': 'å…¶ä»–æƒç›Šå·¥å…·:ä¼˜å…ˆè‚¡', 'lending_funds': 'èå‡ºèµ„é‡‘',
    'acc_receivable': 'åº”æ”¶æ¬¾é¡¹', 'st_fin_payable': 'åº”ä»˜çŸ­æœŸèèµ„æ¬¾', 'payables': 'åº”ä»˜æ¬¾é¡¹',
    'hfs_assets': 'æŒæœ‰å¾…å”®çš„èµ„äº§', 'hfs_sales': 'æŒæœ‰å¾…å”®çš„è´Ÿå€º', 'cost_fin_assets': 'èå‡ºèµ„é‡‘',
    'fair_value_fin_assets': 'ä»¥å…¬å…ä»·å€¼è®¡é‡çš„é‡‘èèµ„äº§', 'contract_assets': 'åˆåŒèµ„äº§', 'contract_liab': 'åˆåŒè´Ÿå€º',
    'accounts_receiv_bill': 'åº”æ”¶ç¥¨æ®åŠåº”æ”¶è´¦æ¬¾', 'accounts_pay': 'åº”ä»˜ç¥¨æ®åŠåº”ä»˜è´¦æ¬¾', 'oth_rcv_total': 'å…¶ä»–åº”æ”¶æ¬¾åˆè®¡',
    'fix_assets_total': 'å›ºå®šèµ„äº§åˆè®¡', 'cip_total': 'åœ¨å»ºå·¥ç¨‹åˆè®¡', 'oth_pay_total': 'å…¶ä»–åº”ä»˜æ¬¾åˆè®¡',
    'long_pay_total': 'é•¿æœŸåº”ä»˜æ¬¾åˆè®¡', 'debt_invest': 'å€ºæƒæŠ•èµ„', 'oth_debt_invest': 'å…¶ä»–å€ºæƒæŠ•èµ„',
}

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="AIé‡åŒ–æŠ•ç ”å¹³å° V3 - å…¨åŠŸèƒ½ç‰ˆ", page_icon="ğŸ†", layout="wide")

# --- åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ (å¢å¼ºç‰ˆï¼Œä½¿ç”¨æ–°çš„å¼•æ“æ–‡ä»¶) ---
@st.cache_resource
def initialize_components():
    """åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒæœåŠ¡å’Œç®¡ç†å™¨"""
    try:
        data_manager = data.DataManager()
        # ã€ä¿®æ­£ã€‘åˆå§‹åŒ–AIOrchestratoræ—¶ä¼ å…¥data_manager
        ai_orchestrator = intelligence.AIOrchestrator(config.AI_MODEL_CONFIG, data_manager)
        # ä»æ–°çš„quant_engineä¸­åˆå§‹åŒ–æ‰€æœ‰ç±»
        factor_factory = quant_engine.FactorFactory(_data_manager=data_manager)
        factor_processor = quant_engine.FactorProcessor(_data_manager=data_manager)
        factor_analyzer = quant_engine.FactorAnalyzer(_data_manager=data_manager)
        task_runner = quant_engine.AutomatedTasks(data_manager, factor_factory)
        market_profiler = quant_engine.MarketProfile(data_manager=data_manager)
        return data_manager, factor_factory, ai_orchestrator, factor_processor, task_runner, market_profiler, factor_analyzer
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return None, None, None, None, None, None, None

data_manager, factor_factory, ai_orchestrator, factor_processor, task_runner, market_profiler, factor_analyzer = initialize_components()
if not data_manager:
    st.stop()

# AdaptiveAlphaStrategy éœ€è¦ä¸€ä¸ªåŒ…å«å†å²ä»·æ ¼çš„DataFrameï¼Œæˆ‘ä»¬åœ¨åå°å‡†å¤‡å¥½
@st.cache_resource
def preload_prices_for_adaptive_strategy(stock_codes, start, end):
    prices_dict = data_manager.run_batch_download(stock_codes, start, end)
    all_prices_df = pd.DataFrame({
        stock: df.set_index('trade_date')['close']
        for stock, df in prices_dict.items() if df is not None and not df.empty
    }).sort_index()
    all_prices_df.index = pd.to_datetime(all_prices_df.index)
    all_prices_df.dropna(axis=1, how='all', inplace=True)
    return all_prices_df

# --- ä¼šè¯çŠ¶æ€åˆå§‹åŒ– ---
if 'selected_stock' not in st.session_state:
    st.session_state.selected_stock = None

# --- ä¾§è¾¹æ  ---
st.sidebar.title("æŠ•ç ”å¹³å°æ§åˆ¶å° V3")
st.sidebar.markdown("---")

@st.cache_data(ttl=3600)
def get_stock_list():
    # å¢åŠ è¿‡æ»¤ï¼Œå»é™¤STå’Œæœªä¸Šå¸‚çš„
    stocks = data_manager.get_stock_basic()

    # å¢åŠ å¥å£®æ€§æ£€æŸ¥ï¼šç¡®ä¿å…³é”®åˆ—å­˜åœ¨
    if stocks is None or stocks.empty:
        st.error("æ— æ³•è·å–è‚¡ç¥¨åŸºç¡€æ•°æ®ã€‚")
        return pd.DataFrame()

    # ã€ä¿®æ­£ã€‘ç§»é™¤å¯¹ list_status çš„é‡å¤è¿‡æ»¤ã€‚
    # å› ä¸ºåœ¨ data.py çš„ get_stock_basic ä¸­å·²é€šè¿‡å‚æ•° list_status='L' åœ¨APIå±‚é¢å®Œæˆè¿‡æ»¤ã€‚
    # Tushare API å› æ­¤ä¸å†è¿”å›è¯¥åˆ—ï¼Œæ­¤å¤„çš„æ£€æŸ¥å’Œè­¦å‘Šå¯ä»¥å®‰å…¨ç§»é™¤ã€‚

    if 'name' in stocks.columns:
        stocks = stocks[~stocks['name'].str.contains('ST')]
    else:
        st.warning("è­¦å‘Šï¼š'name' åˆ—ä¸å­˜åœ¨ï¼Œæ— æ³•è¿‡æ»¤STè‚¡ç¥¨ã€‚")

    return stocks

stock_list = get_stock_list()
if stock_list is not None and not stock_list.empty:
    stock_options = stock_list['ts_code'] + " " + stock_list['name']

    # ã€é‡æ„ã€‘ä½¿ç”¨ st.session_state æ¥æ§åˆ¶ selectbox
    # å¦‚æœ session_state ä¸­æœ‰æ¥è‡ªâ€œæ™ºèƒ½é€‰è‚¡æ’åâ€çš„ç‚¹å‡»ï¼Œå°±ç”¨å®ƒ
    if 'selected_stock' in st.session_state and st.session_state.selected_stock and st.session_state.selected_stock in stock_options.tolist():
        default_index = stock_options.tolist().index(st.session_state.selected_stock)
    else: # å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
        default_index = stock_options[stock_options.str.contains("è´µå·èŒ…å°")].index[0] if any(stock_options.str.contains("è´µå·èŒ…å°")) else 0

    selected_stock_str = st.sidebar.selectbox("é€‰æ‹©è‚¡ç¥¨:", options=stock_options, index=int(default_index), key="stock_selector")
    ts_code = selected_stock_str.split(" ")[0]
else:
    ts_code = st.sidebar.text_input("è¾“å…¥è‚¡ç¥¨ä»£ç  (å¦‚ 600519.SH):", "600519.SH")

end_date = datetime.now()
start_date = end_date - timedelta(days=365)
start_date_input = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", start_date)
end_date_input = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", end_date)
start_date_str = start_date_input.strftime('%Y%m%d')
end_date_str = end_date_input.strftime('%Y%m%d')
st.sidebar.markdown("---")

# --- ä¸»é¡µé¢ ---
st.title(f"ğŸ† {ts_code} - å…¨åŠŸèƒ½æ·±åº¦æŠ•ç ”")
if stock_list is not None and not stock_list[stock_list['ts_code'] == ts_code].empty:
    info = stock_list[stock_list['ts_code'] == ts_code].iloc[0]
    st.markdown(f"**åç§°:** {info['name']} | **è¡Œä¸š:** {info['industry']} | **ä¸Šå¸‚:** {info['list_date']}")


# --- V2.0 æ–°å¢åˆ†ææ¨¡å— ---
try:
    import index_analyzer
    import industry_analyzer
    index_analyzer_client = index_analyzer.IndexAnalyzer(data_manager)
    # industry_analyzer_client = industry_analyzer.IndustryAnalyzer(data_manager, factor_factory) # å¾…å®ç°
    V2_MODULES_LOADED = True
except ImportError:
    V2_MODULES_LOADED = False


# --- åˆ›å»ºå¤šæ ‡ç­¾é¡µ (V2.2 UX ä¼˜åŒ–) ---
# V2.2 é‡æ„ï¼šæ˜ç¡®å®šä¹‰æ‰€æœ‰æ ‡ç­¾é¡µçš„æœ€ç»ˆç†æƒ³é¡ºåº
all_tabs_ordered = [
    "ğŸ“ˆ ç­–ç•¥çœ‹æ¿",   # V2.3 æ–°å¢
    "ğŸ¯ å¸‚åœºå…¨æ™¯",
    "ğŸ­ è¡Œä¸šé€è§†",
    "ğŸ† æ™ºèƒ½é€‰è‚¡æ’å",
    "ğŸ“ˆ è¡Œæƒ…æ€»è§ˆ",
    "ğŸ’° èµ„é‡‘ä¸ç­¹ç ",
    "ğŸ§¾ æ·±åº¦è´¢åŠ¡",
    "ğŸŒ å®è§‚ç¯å¢ƒ",
    "ğŸ¤– AIç»¼åˆæŠ¥å‘Š",
    "ğŸ”¬ å› å­åˆ†æå™¨",
    "ğŸš€ å›æµ‹å®éªŒå®¤",
    "ğŸ”¬ æ¨¡å‹è®­ç»ƒå®¤", # V2.3 æ–°å¢
    "âš™ï¸ ç³»ç»Ÿä»»åŠ¡"
]

# å®šä¹‰å“ªäº›æ ‡ç­¾é¡µä¾èµ– V2 æ¨¡å—
V2_TABS = ["ğŸ¯ å¸‚åœºå…¨æ™¯", "ğŸ­ è¡Œä¸šé€è§†"]

# æ ¹æ®æ¨¡å—åŠ è½½æƒ…å†µï¼ŒåŠ¨æ€ç”Ÿæˆæœ€ç»ˆçš„æ ‡ç­¾é¡µåˆ—è¡¨
if V2_MODULES_LOADED:
    tab_list = all_tabs_ordered
else:
    # å¦‚æœ V2 æ¨¡å—åŠ è½½å¤±è´¥ï¼Œåˆ™ä»ç†æƒ³é¡ºåºä¸­ç§»é™¤å¯¹åº”çš„æ ‡ç­¾é¡µ
    tab_list = [tab for tab in all_tabs_ordered if tab not in V2_TABS]

tabs = st.tabs(tab_list)

# æ ¹æ®æœ€ç»ˆç”Ÿæˆçš„ tab_list åŠ¨æ€è§£åŒ…ï¼Œæ›´åŠ å¥å£®
# ä½¿ç”¨ dict comprehension å’Œ globals() æ¥åŠ¨æ€åˆ›å»ºå˜é‡ï¼Œé¿å…å¤æ‚çš„ if/else
tab_mapping = {tab.replace(" ", "_").replace("ğŸ†_", "").replace("ğŸ“ˆ_", "").replace("ğŸ’°_", "").replace("ğŸ§¾_", "").replace("ğŸŒ_", "").replace("ğŸ¯_", "").replace("ğŸ­_", "").replace("ğŸ¤–_", "").replace("ğŸ”¬_", "").replace("ğŸš€_", "").replace("âš™ï¸_", ""): tab_obj for tab, tab_obj in zip(tab_list, tabs)}
globals().update(tab_mapping)

# ä¸º V2 æ¨¡å—åˆ›å»ºå ä½ç¬¦ï¼Œä»¥é˜²åŠ è½½å¤±è´¥
if not V2_MODULES_LOADED:
    tab_market, tab_industry = None, None
else:
    tab_market = tab_mapping.get('å¸‚åœºå…¨æ™¯')
    tab_industry = tab_mapping.get('è¡Œä¸šé€è§†')

# ä¸ºäº†ä»£ç å¯è¯»æ€§ï¼Œä¸ºå‡ ä¸ªæ ¸å¿ƒtabåˆ›å»ºåˆ«å
tab_strategy_board = tab_mapping.get('ç­–ç•¥çœ‹æ¿') # V2.3 æ–°å¢
tab_ranker = tab_mapping.get('æ™ºèƒ½é€‰è‚¡æ’å')
tab_main = tab_mapping.get('è¡Œæƒ…æ€»è§ˆ')
tab_funds = tab_mapping.get('èµ„é‡‘ä¸ç­¹ç ')
tab_finance = tab_mapping.get('æ·±åº¦è´¢åŠ¡')
tab_macro = tab_mapping.get('å®è§‚ç¯å¢ƒ')
tab_ai = tab_mapping.get('AIç»¼åˆæŠ¥å‘Š')
tab_analyzer = tab_mapping.get('å› å­åˆ†æå™¨')
tab_backtest = tab_mapping.get('å›æµ‹å®éªŒå®¤')
tab_trainer = tab_mapping.get('æ¨¡å‹è®­ç»ƒå®¤') # V2.3 æ–°å¢
tab_tasks = tab_mapping.get('ç³»ç»Ÿä»»åŠ¡')


# --- 0. ç­–ç•¥çœ‹æ¿ (V2.3 æ–°å¢) ---
if tab_strategy_board:
    with tab_strategy_board:
        st.subheader("æ¯æ—¥AIæŠ•ç ”æ™¨æŠ¥ä¸ç­–ç•¥æŒä»“")
        st.markdown("æ­¤çœ‹æ¿å±•ç¤ºç”±åå°è‡ªåŠ¨åŒ–å·¥ä½œæµåœ¨æ¯æ—¥å¼€ç›˜å‰ï¼ˆé»˜è®¤ 08:00ï¼‰ç”Ÿæˆçš„æœ€æ–°ç­–ç•¥åˆ†æç»“æœã€‚")

        # è·å–æœ€æ–°äº¤æ˜“æ—¥
        try:
            cal_df = data_manager.pro.trade_cal(exchange='', start_date=(datetime.now() - timedelta(days=5)).strftime('%Y%m%d'), end_date=datetime.now().strftime('%Y%m%d'))
            report_date = cal_df[cal_df['is_open'] == 1]['cal_date'].max()
        except Exception:
            report_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
        
        st.info(f"æ­£åœ¨åŠ è½½ **{report_date}** çš„æ™¨æŠ¥...")

        # ä»æ•°æ®åº“åŠ è½½æ™¨æŠ¥
        try:
            with data_manager.engine.connect() as conn:
                query = text("SELECT report_content FROM ai_reports WHERE trade_date = :date AND ts_code = 'STRATEGY_MORNING_REPORT'")
                report_content = conn.execute(query, {'date': report_date}).scalar_one_or_none()

            if report_content:
                st.markdown(report_content)
            else:
                st.warning(f"æœªèƒ½åœ¨æ•°æ®åº“ä¸­æ‰¾åˆ° {report_date} çš„æ™¨æŠ¥ã€‚è¯·ç¡®è®¤åå° `run_strategy_daily.py` ä»»åŠ¡æ˜¯å¦å·²æˆåŠŸæ‰§è¡Œã€‚")
        except Exception as e:
            st.error(f"åŠ è½½æ™¨æŠ¥æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯: {e}")


# --- 1. æ™ºèƒ½é€‰è‚¡æ’å ---
# V2.3 å¥å£®æ€§ä¼˜åŒ–ï¼šå…¨é¢ä½¿ç”¨ tab_objects.get()
if tab_ranker:
    with tab_ranker:
        st.subheader("æ™ºèƒ½é€‰è‚¡ä¸è¡Œä¸šè½®åŠ¨åˆ†æ")
        st.markdown("æ„å»ºæ‚¨çš„ä¸“å±å¤šå› å­æ¨¡å‹ï¼Œç³»ç»Ÿå°†ä»**è¡Œä¸š**å’Œ**ä¸ªè‚¡**ä¸¤ä¸ªå±‚é¢è¿›è¡Œç»¼åˆæ‰“åˆ†æ’åï¼ŒåŠ©æ‚¨å®ç°â€œå…ˆé€‰èµ›é“ã€å†é€‰èµ›é©¬â€çš„ä¸“ä¸šæŠ•ç ”ã€‚")
    # --- 1. è·å–æœ€æ–°äº¤æ˜“æ—¥ ---
    try:
        cal_df = data_manager.pro.trade_cal(exchange='', start_date=(datetime.now() - timedelta(days=5)).strftime('%Y%m%d'), end_date=datetime.now().strftime('%Y%m%d'))
        latest_trade_date = cal_df[cal_df['is_open'] == 1]['cal_date'].max()
        st.info(f"æ•°æ®åŸºäºæœ€æ–°å·²è®¡ç®—äº¤æ˜“æ—¥: **{latest_trade_date}**")
    except Exception as e:
        st.error(f"æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥: {e}")
        latest_trade_date = None

    if latest_trade_date:
        # --- 2. ç”¨æˆ·é€‰æ‹©å› å­ä¸æƒé‡ ---
        st.markdown("#### (1) é…ç½®æ‚¨çš„å¤šå› å­æ¨¡å‹")
        # ã€V2.2 é‡æ„ã€‘ä»ç»Ÿä¸€çš„æ•°æ®ç®¡é“è„šæœ¬ä¸­å¯¼å…¥å› å­åˆ—è¡¨ï¼Œç¡®ä¿æºå”¯ä¸€
        from run_daily_pipeline import FACTORS_TO_CALCULATE as available_factors

        cols = st.columns(4)
        factor_direction = {
            'pe_ttm': -1, 'roe': 1, 'growth_revenue_yoy': 1, 'debt_to_assets': -1,
            'momentum': 1, 'volatility': -1, 'net_inflow_ratio': 1,
            'holder_num_change_ratio': -1, # è‚¡ä¸œäººæ•°å˜åŒ–ç‡è¶Šå°è¶Šå¥½
            'major_shareholder_net_buy_ratio': 1, # é‡è¦è‚¡ä¸œå‡€å¢æŒæ¯”ç‡è¶Šå¤§è¶Šå¥½
            'top_list_net_buy_amount': 1, # é¾™è™æ¦œå‡€ä¹°å…¥é¢è¶Šå¤§è¶Šå¥½
            'dividend_yield': 1, # è‚¡æ¯ç‡è¶Šé«˜è¶Šå¥½
            'forecast_growth_rate': 1, # é¢„å‘Šå¢é•¿ç‡è¶Šé«˜è¶Šå¥½
            'repurchase_ratio': 1, # å›è´­æ¯”ä¾‹è¶Šé«˜è¶Šå¥½
            'block_trade_ratio': 1 # å¤§å®—äº¤æ˜“å æ¯”è¶Šé«˜ï¼Œè¯´æ˜è¯¥è‚¡å¯èƒ½åœ¨æœºæ„é—´å…³æ³¨åº¦é«˜
        }

        # --- V2.1 é‡æ„ï¼šæ˜ç¡®å®šä¹‰å› å­åˆ†ç±»åˆ—è¡¨ ---
        VALUE_FACTORS = ['pe_ttm', 'dividend_yield', 'repurchase_ratio']
        QUALITY_GROWTH_FACTORS = ['roe', 'growth_revenue_yoy', 'debt_to_assets', 'forecast_growth_rate']
        TECH_FINANCE_FACTORS = ['momentum', 'volatility', 'net_inflow_ratio', 'block_trade_ratio']
        CHIP_FACTORS = ['holder_num_change_ratio', 'major_shareholder_net_buy_ratio', 'top_list_net_buy_amount']

        with cols[0]:
            st.multiselect("ä»·å€¼/å›æŠ¥å› å­", [f for f in available_factors if f in VALUE_FACTORS], default=['pe_ttm', 'dividend_yield', 'repurchase_ratio'], key="value_factors")
        with cols[1]:
            st.multiselect("è´¨é‡/æˆé•¿å› å­", [f for f in available_factors if f in QUALITY_GROWTH_FACTORS], default=['roe', 'growth_revenue_yoy', 'forecast_growth_rate'], key="quality_factors")
        with cols[2]:
            st.multiselect("æŠ€æœ¯/èµ„é‡‘å› å­", [f for f in available_factors if f in TECH_FINANCE_FACTORS], default=['momentum', 'net_inflow_ratio'], key="tech_factors")
        with cols[3]:
            st.multiselect("ç­¹ç å› å­", [f for f in available_factors if f in CHIP_FACTORS], default=['holder_num_change_ratio', 'major_shareholder_net_buy_ratio'], key="chip_factors")

        user_selection = st.session_state.value_factors + st.session_state.quality_factors + st.session_state.tech_factors + st.session_state.chip_factors
        # --- 3. æ‰§è¡Œæ’å ---
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½æ’å", use_container_width=True):
            if not user_selection:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå› å­ã€‚")
            else:
                with st.spinner("æ­£åœ¨ä»å› å­åº“æå–æ•°æ®å¹¶è®¡ç®—è¡Œä¸šä¸ä¸ªè‚¡ç»¼åˆå¾—åˆ†..."):
                    try:
                        # --- A. ä»æ•°æ®åº“æŸ¥è¯¢æ‰€æœ‰é€‰ä¸­å› å­çš„æ•°æ® ---
                        query = text(f"""
                            SELECT ts_code, factor_name, factor_value
                            FROM factors_exposure
                            WHERE trade_date = '{latest_trade_date}'
                            AND factor_name IN ({','.join([f"'{f}'" for f in user_selection])})
                        """)
                        with data_manager.engine.connect() as conn:
                            all_factor_data = pd.read_sql(query, conn)

                        # --- B. æ•°æ®å¤„ç†ï¼šå°†é•¿è¡¨è½¬æ¢ä¸ºå®½è¡¨ ---
                        factor_table = all_factor_data.pivot(index='ts_code', columns='factor_name', values='factor_value').dropna()

                        # --- C. åˆå¹¶è¡Œä¸šä¿¡æ¯ ---
                        full_stock_list = get_stock_list()
                        factor_table_with_industry = factor_table.merge(full_stock_list[['ts_code', 'name', 'industry']], on='ts_code')

                        # --- D. ã€æ–°å¢ã€‘è®¡ç®—è¡Œä¸šç»¼åˆå¾—åˆ† ---
                        st.markdown("---")
                        st.markdown("#### (2) è¡Œä¸šç»¼åˆå¾—åˆ†æ’å")
                        industry_factors = factor_table_with_industry.groupby('industry')[user_selection].mean()
                        processed_industry_factors = industry_factors.apply(lambda x: (x - x.mean()) / x.std())
                        for factor, direction in factor_direction.items():
                            if factor in processed_industry_factors.columns:
                                processed_industry_factors[factor] *= direction
                        processed_industry_factors['è¡Œä¸šç»¼åˆå¾—åˆ†'] = processed_industry_factors.mean(axis=1)
                        industry_rank = processed_industry_factors.sort_values('è¡Œä¸šç»¼åˆå¾—åˆ†', ascending=False)

                        st.dataframe(industry_rank.style.format('{:.2f}'))
                        st.bar_chart(industry_rank['è¡Œä¸šç»¼åˆå¾—åˆ†'].head(15))

                        # --- E. è®¡ç®—ä¸ªè‚¡ç»¼åˆå¾—åˆ† ---
                        st.markdown("---")
                        st.markdown("#### (3) ä¸ªè‚¡ç»¼åˆå¾—åˆ†æ’å")
                        processed_stock_factors = factor_table.apply(lambda x: (x - x.mean()) / x.std())
                        for factor, direction in factor_direction.items():
                            if factor in processed_stock_factors.columns:
                                processed_stock_factors[factor] *= direction
                        processed_stock_factors['ç»¼åˆå¾—åˆ†'] = processed_stock_factors.mean(axis=1)

                        final_rank = processed_stock_factors.merge(full_stock_list[['ts_code', 'name', 'industry']], on='ts_code')
                        final_rank = final_rank.sort_values('ç»¼åˆå¾—åˆ†', ascending=False).reset_index(drop=True)

                        # --- F. ä¸ªè‚¡ç»“æœå±•ç¤ºä¸äº¤äº’ ---
                        final_rank_display = final_rank[['ts_code', 'name', 'industry', 'ç»¼åˆå¾—åˆ†']].head(100)
                        
                        st.caption("ğŸ’¡ å°æç¤ºï¼šç›´æ¥ç‚¹å‡»ä¸‹æ–¹è¡¨æ ¼ä¸­çš„ä»»æ„ä¸€è¡Œï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è·³è½¬åˆ°è¯¥è‚¡ç¥¨çš„æ·±åº¦åˆ†æé¡µé¢ã€‚")

                        # ã€äº¤äº’ä¿®å¤ã€‘ä½¿ç”¨ st.data_editor æ›¿ä»£ st.dataframeï¼Œä»¥æ•è·è¡Œé€‰æ‹©äº‹ä»¶
                        # å°†é€‰æ‹©çŠ¶æ€å­˜å‚¨åœ¨ session_state ä¸­
                        if "selected_rank_row" not in st.session_state:
                            st.session_state.selected_rank_row = None
                        
                        edited_df = st.data_editor(
                            final_rank_display, 
                            hide_index=True, 
                            disabled=final_rank_display.columns, # è®¾ç½®æ‰€æœ‰åˆ—ä¸ºä¸å¯ç¼–è¾‘
                            on_select="rerun", # å½“é€‰æ‹©å˜åŒ–æ—¶ï¼Œé‡æ–°è¿è¡Œè„šæœ¬
                            key="rank_selector"
                        )

                        # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œè¢«é€‰ä¸­
                        if st.session_state.rank_selector and st.session_state.rank_selector.get("selection", {}).get("rows"):
                            selected_index = st.session_state.rank_selector["selection"]["rows"][0]
                            selected_row = final_rank_display.iloc[selected_index]
                            
                            selected_ts_code = selected_row['ts_code']
                            selected_name = selected_row['name']
                            
                            # æ›´æ–°å…¨å±€ session_state å¹¶è§¦å‘é‡è·‘ï¼Œè®©ä¾§è¾¹æ çš„ selectbox æ›´æ–°
                            st.session_state.selected_stock = f"{selected_ts_code} {selected_name}"
                            st.rerun()

                    except Exception as e:
                        st.error(f"æ’åè®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        st.exception(e)

# --- 2. è¡Œæƒ…æ€»è§ˆ ---
if tab_main:
    with tab_main:
        st.subheader("æ—¥Kçº¿å›¾ (åå¤æƒ) & ç»¼åˆæŒ‡æ ‡")
        df_adj = data_manager.get_adjusted_daily(ts_code, start_date_str, end_date_str, adj='hfq')
        if df_adj is not None and not df_adj.empty:
            # --- 1. æ•°æ®è·å–ä¸åˆå¹¶ ---
            # è·å–æ¯æ—¥åŸºæœ¬é¢æŒ‡æ ‡ï¼ˆPEã€æ¢æ‰‹ç‡ç­‰ï¼‰
            df_basic = data_manager.get_daily_basic(ts_code, start_date_str, end_date_str)
            if df_basic is not None and not df_basic.empty:
                # ã€ä¿®æ­£ã€‘åœ¨åˆå¹¶å‰ï¼Œç¡®ä¿ä¸¤ä¸ªDataFrameçš„'trade_date'åˆ—éƒ½æ˜¯datetimeç±»å‹
                df_adj['trade_date'] = pd.to_datetime(df_adj['trade_date'])
                df_basic['trade_date'] = pd.to_datetime(df_basic['trade_date'])
                # å°†åŸºç¡€æŒ‡æ ‡åˆå¹¶åˆ°ä¸»æ•°æ®æ¡†ä¸­
                df_adj = pd.merge(df_adj, df_basic[['trade_date', 'pe_ttm', 'turnover_rate']], on='trade_date', how='left')

            # --- 2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ ---
            df_adj['EMA20'] = df_adj['close'].ewm(span=20, adjust=False).mean()
            df_adj['EMA60'] = df_adj['close'].ewm(span=60, adjust=False).mean()
            df_adj['EMA120'] = df_adj['close'].ewm(span=120, adjust=False).mean()
            df_adj['Vol_EMA20'] = df_adj['vol'].ewm(span=20, adjust=False).mean()

            # --- 3. ç»˜å›¾ (å¢å¼ºç‰ˆï¼Œ4ä¸ªå­å›¾) ---
            fig = make_subplots(
                rows=4, cols=1, shared_xaxes=True,
                vertical_spacing=0.03,
                row_heights=[0.55, 0.15, 0.15, 0.15] # è°ƒæ•´å„å­å›¾é«˜åº¦å æ¯”
            )

            # å›¾1: Kçº¿ä¸å‡çº¿
            fig.add_trace(go.Candlestick(x=df_adj['trade_date'], open=df_adj['open'], high=df_adj['high'], low=df_adj['low'], close=df_adj['close'], name='Kçº¿'), row=1, col=1)
            fig.add_trace(go.Scatter(x=df_adj['trade_date'], y=df_adj['EMA20'], mode='lines', name='EMA20', line=dict(color='yellow', width=1)), row=1, col=1)
            fig.add_trace(go.Scatter(x=df_adj['trade_date'], y=df_adj['EMA60'], mode='lines', name='EMA60', line=dict(color='cyan', width=1)), row=1, col=1)
            fig.add_trace(go.Scatter(x=df_adj['trade_date'], y=df_adj['EMA120'], mode='lines', name='EMA120', line=dict(color='magenta', width=1)), row=1, col=1)

            # å›¾2: æˆäº¤é‡
            fig.add_trace(go.Bar(x=df_adj['trade_date'], y=df_adj['vol'], name='æˆäº¤é‡', marker_color='lightblue'), row=2, col=1)
            fig.add_trace(go.Scatter(x=df_adj['trade_date'], y=df_adj['Vol_EMA20'], mode='lines', name='æˆäº¤é‡EMA20', line=dict(color='orange', width=1)), row=2, col=1)

            # å›¾3: å¸‚ç›ˆç‡ (PE-TTM)
            if 'pe_ttm' in df_adj.columns:
                fig.add_trace(go.Scatter(x=df_adj['trade_date'], y=df_adj['pe_ttm'], mode='lines', name='å¸‚ç›ˆç‡PE(TTM)', line=dict(color='lightgreen', width=1.5)), row=3, col=1)
                fig.update_yaxes(title_text="PE(TTM)", row=3, col=1)

            # å›¾4: æ¢æ‰‹ç‡
            if 'turnover_rate' in df_adj.columns:
                fig.add_trace(go.Bar(x=df_adj['trade_date'], y=df_adj['turnover_rate'], name='æ¢æ‰‹ç‡(%)', marker_color='violet'), row=4, col=1)
                fig.update_yaxes(title_text="æ¢æ‰‹ç‡(%)", row=4, col=1)

            fig.update_layout(
                title_text=f"{ts_code} - æŠ€æœ¯ã€ä¼°å€¼ä¸æƒ…ç»ªç»¼åˆè§†å›¾",
                xaxis_rangeslider_visible=False,
                template="plotly_dark",
                height=800  # å¢åŠ å›¾è¡¨æ€»é«˜åº¦ä»¥å®¹çº³æ›´å¤šå­å›¾
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æ— æ³•è·å–å¤æƒè¡Œæƒ…æ•°æ®ã€‚")

# --- 2. èµ„é‡‘ä¸ç­¹ç  ---
if tab_funds:
    with tab_funds:
        st.subheader("èµ„é‡‘æµå‘ & è‚¡ä¸œç»“æ„ (V2.1 å¢å¼º)")

    # --- Part 1: åŸæœ‰èµ„é‡‘æµåˆ†æ ---
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**ä¸»åŠ›èµ„é‡‘æµ (è¿‘30æ—¥)**")
        df_flow = data_manager.get_moneyflow(ts_code, (end_date - timedelta(days=30)).strftime('%Y%m%d'), end_date_str)
        if df_flow is not None and not df_flow.empty:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=df_flow['trade_date'], y=df_flow['net_mf_amount'], name='å‡€æµå…¥é¢'))
            fig.update_layout(title="ä¸»åŠ›èµ„é‡‘å‡€æµå…¥(ä¸‡å…ƒ)", template="plotly_dark", height=300, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.markdown("**åŒ—å‘èµ„é‡‘æŒè‚¡æ¯”ä¾‹**")
        df_hk = data_manager.get_hk_hold(ts_code, start_date_str, end_date_str)
        if df_hk is not None and not df_hk.empty:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df_hk['trade_date'], y=df_hk['ratio'], mode='lines', name='æŒè‚¡æ¯”ä¾‹(%)'))
            fig.update_layout(title="åŒ—å‘èµ„é‡‘æŒè‚¡æ¯”ä¾‹(%)", template="plotly_dark", height=300, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    # --- Part 2: V2.1 æ–°å¢ç­¹ç åˆ†æ ---
    col3, col4 = st.columns(2)
    with col3:
        st.markdown("**è‚¡ä¸œäººæ•°å˜åŒ–è¶‹åŠ¿**")
        df_holder_num = data_manager.get_holder_number(ts_code)
        if df_holder_num is not None and not df_holder_num.empty and len(df_holder_num) > 1:
            df_holder_num['end_date'] = pd.to_datetime(df_holder_num['end_date'])
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df_holder_num['end_date'], y=df_holder_num['holder_num'], mode='lines+markers', name='è‚¡ä¸œäººæ•°'))
            fig.update_layout(title="è‚¡ä¸œäººæ•°", template="plotly_dark", height=300, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æš‚æ— è¶³å¤Ÿçš„è‚¡ä¸œäººæ•°æ•°æ®ã€‚")

    with col4:
        st.markdown("**é¾™è™æ¦œå‡€ä¹°å…¥ (è¿‘90æ—¥)**")
        df_top_list_hist = data_manager.get_top_list(start_date=(end_date - timedelta(days=90)).strftime('%Y%m%d'), end_date=end_date_str)
        if df_top_list_hist is not None and not df_top_list_hist.empty:
            df_top_list_hist['trade_date'] = pd.to_datetime(df_top_list_hist['trade_date'])
            stock_top_list = df_top_list_hist[df_top_list_hist['ts_code'] == ts_code]
            if not stock_top_list.empty:
                 fig = go.Figure()
                 fig.add_trace(go.Bar(x=stock_top_list['trade_date'], y=stock_top_list['net_amount'], name='é¾™è™æ¦œå‡€ä¹°å…¥é¢'))
                 fig.update_layout(title="é¾™è™æ¦œå‡€ä¹°å…¥(ä¸‡å…ƒ)", template="plotly_dark", height=300, margin=dict(l=20, r=20, t=40, b=20))
                 st.plotly_chart(fig, use_container_width=True)
            else:
                 st.info("è¯¥è‚¡è¿‘90æ—¥æœªç™»ä¸Šé¾™è™æ¦œã€‚")
        else:
            st.warning("æš‚æ— é¾™è™æ¦œæ•°æ®ã€‚")

    st.markdown("**é‡è¦è‚¡ä¸œå¢å‡æŒ (è¿‘ä¸€å¹´)**")
    df_holder_trade = data_manager.get_holder_trade(ts_code, start_date= (end_date - timedelta(days=365)).strftime('%Y%m%d'), end_date=end_date_str)
    if df_holder_trade is not None and not df_holder_trade.empty:
        df_display = df_holder_trade.sort_values(by='ann_date', ascending=True)
        df_display = df_display[['ann_date', 'holder_name', 'in_de', 'change_ratio', 'avg_price']].rename(columns=COLUMN_MAPPING)
        st.dataframe(df_display, use_container_width=True)
    else:
        st.info("è¯¥è‚¡è¿‘ä¸€å¹´æ— é‡è¦è‚¡ä¸œå¢å‡æŒè®°å½•ã€‚")

    st.markdown("**å¤§å®—äº¤æ˜“æ˜ç»† (è¿‘90æ—¥)**")
    df_block_trade = data_manager.get_block_trade(start_date=(end_date - timedelta(days=90)).strftime('%Y%m%d'), end_date=end_date_str)
    if df_block_trade is not None and not df_block_trade.empty:
        stock_block_trade = df_block_trade[df_block_trade['ts_code'] == ts_code]
        if not stock_block_trade.empty:
            df_display = stock_block_trade.sort_values(by='trade_date', ascending=True)
            # ä¿®æ­£ï¼š'price'åˆ—å·²åŠ å…¥ç¿»è¯‘å­—å…¸
            df_display = df_display[['trade_date', 'price', 'vol', 'amount', 'buyer', 'seller']].rename(columns=COLUMN_MAPPING)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        else:
            st.info("è¯¥è‚¡è¿‘90æ—¥æ— å¤§å®—äº¤æ˜“è®°å½•ã€‚")
    else:
        st.info("è¿‘90æ—¥æ— å¤§å®—äº¤æ˜“è®°å½•ã€‚")


    st.markdown("**å‰åå¤§æµé€šè‚¡ä¸œ (æœ€æ–°æŠ¥å‘ŠæœŸ)**")
    # ... (åŸæœ‰è·å–åå¤§è‚¡ä¸œçš„ä»£ç ä¿æŒä¸å˜) ...
    latest_period = ""
    for year_offset in range(2):
        year = end_date.year - year_offset
        periods = [f"{year}1231", f"{year}0930", f"{year}0630", f"{year}0331"]
        for p in periods:
            if p <= end_date.strftime('%Y%m%d'):
                df_holders = data_manager.get_top10_floatholders(ts_code, p)
                if df_holders is not None and not df_holders.empty:
                    latest_period = p
                    break
        if latest_period:
            break

    if latest_period:
        st.info(f"å½“å‰æ˜¾ç¤ºè´¢æŠ¥å‘¨æœŸ: {latest_period}")
        # ä¿®æ­£ï¼šç¡®ä¿æ‰€æœ‰åˆ—éƒ½è¢«ç¿»è¯‘
        df_display = df_holders.rename(columns=COLUMN_MAPPING)
        st.dataframe(df_display, use_container_width=True, height=385, hide_index=True)
    else:
        st.warning("æœªèƒ½è·å–å‰åå¤§æµé€šè‚¡ä¸œæ•°æ®ã€‚")

# --- 3. æ·±åº¦è´¢åŠ¡ ---
if tab_finance:
    with tab_finance:
        st.subheader("è´¢åŠ¡æŠ¥è¡¨ä¸å‰ç»æŒ‡æ ‡ (V2.1 å¢å¼º)")

    # --- Part 1: V2.1 æ–°å¢è´¢åŠ¡å‰ç» ---
    st.markdown(f"**ä¸šç»©å¿«æŠ¥ (æœ€æ–°)**")
    # --- V2.1 é‡æ„ï¼šåˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„å‡½æ•°æ¥å¤„ç†è½¬ç½®å’Œç¿»è¯‘ ---
    def display_transposed_df(df: pd.DataFrame):
        if df is None or df.empty:
            return
        # ç¡®ä¿åªå¤„ç†å•è¡Œæ•°æ®
        if len(df) > 1:
             df = df.sort_values(by='ann_date', ascending=False).head(1)

        df_display = df.T.reset_index()
        df_display.columns = ['æŒ‡æ ‡', 'æ•°å€¼']
        # æ ¸å¿ƒä¿®æ­£ï¼šä½¿ç”¨æˆ‘ä»¬å¼ºå¤§çš„æ–°å­—å…¸æ¥ç¿»è¯‘â€œæŒ‡æ ‡â€åˆ—
        df_display['æŒ‡æ ‡'] = df_display['æŒ‡æ ‡'].map(COLUMN_MAPPING).fillna(df_display['æŒ‡æ ‡'])
        df_display['æ•°å€¼'] = df_display['æ•°å€¼'].astype(str)
        st.dataframe(df_display, use_container_width=True, hide_index=True)

    df_express = data_manager.get_express(ts_code, start_date=(end_date - timedelta(days=365)).strftime('%Y%m%d'), end_date=end_date_str)
    if df_express is not None and not df_express.empty:
        df_express['ann_date'] = pd.to_datetime(df_express['ann_date'])
        latest_pit_express = df_express[df_express['ann_date'] <= end_date].sort_values(by='ann_date', ascending=False).head(1)
        if not latest_pit_express.empty:
            display_transposed_df(latest_pit_express)
        else:
            st.info("è¿‘ä¸€å¹´æ— å·²æŠ«éœ²çš„ä¸šç»©å¿«æŠ¥ã€‚")
    else:
        st.info("è¿‘ä¸€å¹´æ— ä¸šç»©å¿«æŠ¥ã€‚")

    st.markdown(f"**ä¸šç»©é¢„å‘Š (æœ€æ–°)**")
    df_forecast = data_manager.get_forecast(ts_code, start_date=(end_date - timedelta(days=365)).strftime('%Y%m%d'), end_date=end_date_str)
    if df_forecast is not None and not df_forecast.empty:
        df_forecast['ann_date'] = pd.to_datetime(df_forecast['ann_date'])
        latest_pit_forecast = df_forecast[df_forecast['ann_date'] <= end_date].sort_values(by='ann_date', ascending=False).head(1)
        if not latest_pit_forecast.empty:
            display_transposed_df(latest_pit_forecast)
        else:
            st.info("è¿‘ä¸€å¹´æ— å·²æŠ«éœ²çš„ä¸šç»©é¢„å‘Šã€‚")
    else:
        st.info("è¿‘ä¸€å¹´æ— ä¸šç»©é¢„å‘Šã€‚")

    st.markdown(f"**å†å²åˆ†çº¢**")
    df_dividend = data_manager.get_dividend(ts_code)
    if df_dividend is not None and not df_dividend.empty:
        df_display = df_dividend.sort_values(by='end_date', ascending=True)
        df_display = df_display[['end_date', 'ann_date', 'div_proc', 'stk_div', 'cash_div_tax']].rename(columns=COLUMN_MAPPING)
        st.dataframe(df_display.head(), use_container_width=True, hide_index=True)
    else:
        st.info("æ— å†å²åˆ†çº¢è®°å½•ã€‚")

    st.markdown(f"**è‚¡ç¥¨å›è´­è®°å½• (è¿‘ä¸€å¹´)**")
    df_repurchase = data_manager.get_repurchase(ts_code, start_date=(end_date - timedelta(days=365)).strftime('%Y%m%d'), end_date=end_date_str)
    if df_repurchase is not None and not df_repurchase.empty:
        df_display = df_repurchase.sort_values(by='ann_date', ascending=True)
        df_display = df_display[['ann_date', 'proc', 'vol', 'amount', 'high_limit', 'low_limit']].rename(columns=COLUMN_MAPPING)
        st.dataframe(df_display, use_container_width=True, hide_index=True)
    else:
        st.info("è¿‘ä¸€å¹´æ— è‚¡ç¥¨å›è´­è®°å½•ã€‚")

    st.markdown("---")
    st.markdown("**è´¢åŠ¡æŠ¥è¡¨æ ¸å¿ƒæ•°æ®**")
    # --- Part 2: åŸæœ‰è´¢åŠ¡æŠ¥è¡¨ ---
    if 'latest_period' in locals() and latest_period:
        st.markdown(f"**åˆ©æ¶¦è¡¨ ({latest_period})**")
        df_income = data_manager.get_income(ts_code, latest_period)
        display_transposed_df(df_income)

        st.markdown(f"**èµ„äº§è´Ÿå€ºè¡¨ ({latest_period})**")
        df_balance = data_manager.get_balancesheet(ts_code, latest_period)
        display_transposed_df(df_balance)
    else:
        st.warning("æœªèƒ½ç¡®å®šæœ€æ–°çš„è´¢æŠ¥å‘¨æœŸï¼Œæ— æ³•åŠ è½½è´¢åŠ¡æŠ¥è¡¨ã€‚")

# --- 4. å®è§‚ç¯å¢ƒ ---
if tab_macro:
    with tab_macro:
        st.subheader("å®è§‚ç»æµæŒ‡æ ‡")
        start_m = f"{end_date.year-2}{end_date.month:02d}"
        end_m = f"{end_date.year}{end_date.month:02d}"
        df_pmi = data_manager.get_cn_pmi(start_m, end_m)
        if df_pmi is not None and not df_pmi.empty:
            # ä¿®å¤å¤§å°å†™é—®é¢˜ï¼šå°†æ‰€æœ‰åˆ—åè½¬ä¸ºå°å†™
            df_pmi.columns = [col.lower() for col in df_pmi.columns]

            fig = go.Figure()
            # æ ¹æ®æœ€æ–°çš„Tushareæ¥å£æ–‡æ¡£ï¼Œåˆ¶é€ ä¸šPMIå­—æ®µä¸º'pmi010000'
            pmi_col = 'pmi010000'
            date_col = 'month' # Tushareæ–‡æ¡£æ˜ç¡®æœˆä»½å­—æ®µä¸º'month'

            if date_col not in df_pmi.columns or pmi_col not in df_pmi.columns:
                st.error(f"PMIæ•°æ®ä¸­æœªæ‰¾åˆ°å…³é”®åˆ—ã€‚éœ€è¦æ—¥æœŸåˆ— ('{date_col}') å’ŒPMIåˆ— ('{pmi_col}')ã€‚å¯ç”¨åˆ—ï¼š{df_pmi.columns.tolist()}")
            else:
                fig.add_trace(go.Scatter(x=df_pmi[date_col], y=pd.to_numeric(df_pmi[pmi_col]), name='åˆ¶é€ ä¸šPMI'))
                fig.add_hline(y=50, line_dash="dash", line_color="red", annotation_text="è£æ¯çº¿", annotation_position="bottom right")
                fig.update_layout(title="åˆ¶é€ ä¸šé‡‡è´­ç»ç†äººæŒ‡æ•° (PMI)", template="plotly_dark")
                st.plotly_chart(fig, use_container_width=True)

        df_m = data_manager.get_cn_m(start_m, end_m)
        if df_m is not None and not df_m.empty:
            fig = go.Figure()
            date_col = 'month' if 'month' in df_m.columns else 'stat_month' # å…¼å®¹'month'æˆ–'stat_month'

            if date_col not in df_m.columns:
                st.error("è´§å¸ä¾›åº”é‡æ•°æ®ä¸­æœªæ‰¾åˆ°æ—¥æœŸåˆ— ('month'æˆ–'stat_month')ã€‚")
            else:
                fig.add_trace(go.Bar(x=df_m[date_col], y=df_m['m1_yoy'] - df_m['m2_yoy'], name='M1-M2å‰ªåˆ€å·®'))
                fig.add_hline(y=0, line_dash="dash", line_color="white")
                fig.update_layout(title="M1-M2åŒæ¯”å¢é€Ÿå‰ªåˆ€å·®(%)", template="plotly_dark")
                st.plotly_chart(fig, use_container_width=True)

        df_cpi = data_manager.get_cn_cpi(start_m=start_m, end_m=end_m)
        if df_cpi is not None and not df_cpi.empty:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=df_cpi['month'], y=df_cpi['nt_yoy'], name='CPIå…¨å›½åŒæ¯”(%)'))
            fig.update_layout(title="å±…æ°‘æ¶ˆè´¹ä»·æ ¼æŒ‡æ•° (CPI)", template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

        df_shibor = data_manager.get_shibor(start_date=(end_date - timedelta(days=365)).strftime('%Y%m%d'), end_date=end_date_str)
        if df_shibor is not None and not df_shibor.empty:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df_shibor['date'], y=df_shibor['on'], name='éš”å¤œ', line=dict(width=1)))
            fig.add_trace(go.Scatter(x=df_shibor['date'], y=df_shibor['1w'], name='1å‘¨', line=dict(width=1)))
            fig.add_trace(go.Scatter(x=df_shibor['date'], y=df_shibor['1y'], name='1å¹´', line=dict(width=2)))
            fig.update_layout(title="ä¸Šæµ·é“¶è¡Œé—´åŒä¸šæ‹†æ”¾åˆ©ç‡ (Shibor)", template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

        st.subheader("åŠ¨æ€å¸‚åœºçŠ¶æ€æ„ŸçŸ¥")
        current_regime = market_profiler.get_market_regime(end_date)
        st.metric(label="å½“å‰å¸‚åœºç¯å¢ƒåˆ¤æ–­", value=current_regime)
        st.caption("åŸºäºPMIå’ŒM1-M2å‰ªåˆ€å·®çš„å®è§‚æ¨¡å‹ã€‚ç­–ç•¥åº”æ ¹æ®'ç‰›å¸‚'ã€'ç†Šå¸‚'æˆ–'éœ‡è¡å¸‚'è°ƒæ•´é£é™©åå¥½ã€‚")

# --- V2.0 æ–°å¢: å¸‚åœºå…¨æ™¯ ---
if V2_MODULES_LOADED and tab_market:
    with tab_market:
        st.subheader("å¤§ç›˜æ‹©æ—¶åˆ†æ (æ²ªæ·±300)")
        index_code = '000300.SH' # ä»¥æ²ªæ·±300ä¸ºä¾‹

        with st.spinner("æ­£åœ¨è®¡ç®—å¤§ç›˜ä¼°å€¼..."):
            valuation = index_analyzer_client.get_index_valuation_percentile(index_code, end_date_str)
            timing_signal = index_analyzer_client.generate_timing_signal(index_code, end_date_str)

            if 'error' in valuation:
                st.error("æ— æ³•è·å–å¤§ç›˜ä¼°å€¼æ•°æ®ã€‚")
            else:
                st.metric(label="å½“å‰æ‹©æ—¶ä¿¡å·", value=timing_signal)
                col1, col2 = st.columns(2)
                col1.metric(label="PE(TTM) ç™¾åˆ†ä½", value=f"{valuation['pe_percentile']:.2%}", help=f"å½“å‰PE: {valuation['pe_ttm']:.2f}ã€‚ç™¾åˆ†ä½è¶Šä½ä»£è¡¨ä¼°å€¼è¶Šä¾¿å®œã€‚")
                col2.metric(label="PB ç™¾åˆ†ä½", value=f"{valuation['pb_percentile']:.2%}", help=f"å½“å‰PB: {valuation['pb']:.2f}ã€‚ç™¾åˆ†ä½è¶Šä½ä»£è¡¨ä¼°å€¼è¶Šä¾¿å®œã€‚")
                st.info("æ‹©æ—¶ä¿¡å·åŸºäºPEå’ŒPBåœ¨è¿‡å»5å¹´çš„å†å²ç™¾åˆ†ä½ç”Ÿæˆï¼Œå¯ç”¨äºè¾…åŠ©åˆ¤æ–­å¸‚åœºæ•´ä½“é£é™©ã€‚")

# --- V2.0 æ–°å¢: è¡Œä¸šé€è§† ---
if V2_MODULES_LOADED and tab_industry:
    with tab_industry:
        st.subheader("è¡Œä¸šå› å­æ’åä¸è½®åŠ¨åˆ†æ")
        st.markdown("è®¡ç®—å…¨å¸‚åœºæ‰€æœ‰ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„å¹³å‡å› å­æš´éœ²å€¼ï¼Œå¹¶è¿›è¡Œæ’åºï¼Œç”¨äºå‘ç°å¼ºåŠ¿æˆ–å¼±åŠ¿è¡Œä¸šã€‚")

        # 1. åˆå§‹åŒ–è¡Œä¸šåˆ†æå™¨
        try:
            industry_analyzer_client = industry_analyzer.IndustryAnalyzer(data_manager, factor_factory)
            ANALYZER_READY = True
        except Exception as e:
            st.error(f"åˆå§‹åŒ–è¡Œä¸šåˆ†æå™¨å¤±è´¥: {e}")
            ANALYZER_READY = False

        if ANALYZER_READY:
            # 2. è®¾ç½®åˆ†æå‚æ•°
            col1, col2 = st.columns([1, 1])
            with col1:
                # æä¾›ä¸€ä¸ªå¸¸ç”¨çš„å› å­åˆ—è¡¨ä¾›é€‰æ‹©
                factor_to_rank = st.selectbox(
                    "é€‰æ‹©æ’åå› å­",
                    options=['pe_ttm', 'growth_revenue_yoy', 'momentum', 'net_inflow_ratio', 'roe'],
                    index=0,
                    help="é€‰æ‹©ä¸€ä¸ªå› å­ï¼Œç³»ç»Ÿå°†è®¡ç®—æ¯ä¸ªè¡Œä¸šçš„å¹³å‡å€¼å¹¶è¿›è¡Œæ’åã€‚"
                )
            with col2:
                ranking_asc = st.radio(
                    "æ’åºæ–¹å¼",
                    ("é™åº (é«˜->ä½)", "å‡åº (ä½->é«˜)"),
                    index=0,
                    horizontal=True,
                    help="å¯¹äºPEç­‰ä¼°å€¼å› å­ï¼Œé€šå¸¸é€‰æ‹©å‡åºï¼›å¯¹äºæˆé•¿ã€åŠ¨é‡ç­‰å› å­ï¼Œé€šå¸¸é€‰æ‹©é™åºã€‚"
                )
                ascending = True if "å‡åº" in ranking_asc else False

            if st.button("å¼€å§‹è¡Œä¸šæ’ååˆ†æ"):
                with st.spinner(f"æ­£åœ¨ä»å› å­åº“æŸ¥è¯¢ '{factor_to_rank}' çš„è¡Œä¸šæ’å..."):
                    try:
                        # ã€é‡æ„ã€‘è°ƒç”¨æ–°ç‰ˆåå°é€»è¾‘ï¼Œæ— éœ€å†ä¼ é€’è¿›åº¦æ¡
                        ranked_df = industry_analyzer_client.get_industry_factor_rank(
                            date=end_date_str,
                            factor_name=factor_to_rank,
                            ascending=ascending
                        )

                        if ranked_df.empty:
                            st.warning(f"åœ¨å› å­åº“ä¸­æœªæ‰¾åˆ° {end_date_str} çš„ {factor_to_rank} æ•°æ®ã€‚è¯·ç¡®è®¤åå°è®¡ç®—ä»»åŠ¡æ˜¯å¦å·²æˆåŠŸæ‰§è¡Œã€‚")
                        else:
                            st.success("è¡Œä¸šæ’åæŸ¥è¯¢å®Œæˆï¼")

                            # å±•ç¤ºç»“æœ
                            st.dataframe(ranked_df.style.format('{:.2f}'))

                            st.markdown(f"#### **{factor_to_rank}** å› å­æ’åå‰10è¡Œä¸šå¯è§†åŒ–")
                            top_10_df = ranked_df.head(10) if not ascending else ranked_df.tail(10).sort_values(by='factor_value', ascending=False)
                            st.bar_chart(top_10_df)

                    except Exception as e:
                        st.error(f"è¡Œä¸šåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        st.exception(e)

# --- 5. AIç»¼åˆæŠ¥å‘Š ---
if tab_ai:
    with tab_ai:
        st.subheader("æ··åˆAIæ™ºèƒ½ä½“åˆ†æ")
        st.markdown("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼ŒAIå°†é‡‡é›†å¹¶åˆ†æè¯¥è‚¡çš„ **æŠ€æœ¯ã€èµ„é‡‘ã€è´¢åŠ¡ã€ç­¹ç ã€å®è§‚ã€èˆ†æƒ…** å…­å¤§ç»´åº¦æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½æ·±åº¦ç»¼åˆæŠ•ç ”æŠ¥å‘Šã€‚")
        # FIX 1: Corrected indentation for the 'with' block under the 'if' statement.
        if st.button("ğŸš€ å¯åŠ¨AIæ·±åº¦ç»¼åˆåˆ†æ", help="è°ƒç”¨æ··åˆAIå¼•æ“ï¼Œå¯¹è¯¥è‚¡ç¥¨è¿›è¡Œå…­å¤§ç»´åº¦ã€é€’è¿›å¼åˆ†æï¼Œç”Ÿæˆç»¼åˆæŠ•ç ”æŠ¥å‘Šã€‚"):
            with st.spinner("AIå¼•æ“å¯åŠ¨...æ­£åœ¨æ‰§è¡Œå¤šç»´æ•°æ®é‡‡é›†ä¸æ·±åº¦åˆ†æå·¥ä½œæµ..."):
                try:
                    # æ³¨æ„ï¼šæ­¤å¤„çš„ factor_factory å·²ç»æ˜¯ quant_engine.FactorFactory çš„å®ä¾‹
                    # æ—§ç‰ˆçš„ intelligence.full_analysis_workflow å¯ä»¥ç›´æ¥å…¼å®¹ä½¿ç”¨
                    report, cost = intelligence.full_analysis_workflow(
                        orchestrator=ai_orchestrator, data_manager=data_manager,
                        factor_factory=factor_factory, ts_code=ts_code,
                        date_range=(start_date_str, end_date_str)
                    )
                    st.success("âœ… AIåˆ†æå®Œæˆï¼")
                    st.markdown(report)
                    st.info(f"æœ¬æ¬¡åˆ†æè°ƒç”¨AIæ¨¡å‹ {cost['total_calls']} æ¬¡, é¢„ä¼°æˆæœ¬: ${cost['estimated_cost']:.4f}ã€‚")
                except Exception as e:
                    st.error(f"AIåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                    st.exception(e)

# --- æ–°å¢: 6. å› å­åˆ†æå™¨ ---
if tab_analyzer:
    with tab_analyzer:
        st.subheader("å› å­æœ‰æ•ˆæ€§åˆ†æå®éªŒå®¤")
        st.markdown("é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªå› å­ï¼Œåœ¨æŒ‡å®šçš„è‚¡ç¥¨æ± å’Œæ—¶é—´æ®µå†…ï¼Œè¿›è¡ŒIC/IRåˆ†æå’Œåˆ†å±‚å›æµ‹ï¼Œä»¥è¯„ä¼°å…¶é€‰è‚¡æœ‰æ•ˆæ€§ã€‚")
        # --- å‚æ•°é…ç½® ---
        st.markdown("#### 1. é…ç½®åˆ†æå‚æ•°")
        analyzer_cols = st.columns(3)
        with analyzer_cols[0]:
            # æä¾›ä¸€ä¸ªå¸¸ç”¨çš„å› å­åˆ—è¡¨ä¾›é€‰æ‹©
            factor_to_analyze = st.selectbox(
                "é€‰æ‹©è¦åˆ†æçš„å› å­",
                options=['momentum', 'volatility', 'net_inflow_ratio', 'roe', 'pe_ttm', 'growth_revenue_yoy'],
                index=0,
                key="factor_select"
            )
        with analyzer_cols[1]:
            analyzer_start_date = st.date_input("åˆ†æå¼€å§‹æ—¥æœŸ", datetime(2023, 1, 1), key="analyzer_start")
        with analyzer_cols[2]:
            analyzer_end_date = st.date_input("åˆ†æç»“æŸæ—¥æœŸ", datetime.now() - timedelta(days=1), key="analyzer_end")

        analyzer_stock_pool_options = get_stock_list()['ts_code'] + " " + get_stock_list()['name']
        # é»˜è®¤é€‰æ‹©ä¸€ä¸ªåŒ…å«ä¸åŒè¡Œä¸šçš„è‚¡ç¥¨æ± ä½œä¸ºç¤ºä¾‹
        default_analyzer_pool = [
            s for s in analyzer_stock_pool_options if any(k in s for k in ["å¹³å®‰", "èŒ…å°", "å®å¾·", "ä¸‡ç§‘", "ä¸­ä¿¡"])
        ]
        analyzer_stock_pool = st.multiselect(
            "é€‰æ‹©è‚¡ç¥¨æ±  (å»ºè®®5-20æ”¯)",
            options=analyzer_stock_pool_options,
            default=default_analyzer_pool,
            key="analyzer_pool"
        )
        analyzer_stock_codes = [s.split(" ")[0] for s in analyzer_stock_pool]

        if st.button("ğŸ”¬ å¼€å§‹å› å­åˆ†æ", key="start_factor_analysis"):
            if not analyzer_stock_codes:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ”¯è‚¡ç¥¨è¿›è¡Œåˆ†æã€‚")
            else:
                with st.spinner(f"æ­£åœ¨åˆ†æå› å­ '{factor_to_analyze}'..."):
                    try:
                        # 1. è®¡ç®—å› å­å†å²æˆªé¢æ•°æ®
                        st.info("æ­¥éª¤1: è®¡ç®—å› å­å†å²æˆªé¢æ•°æ®...")
                        dates = pd.date_range(analyzer_start_date, analyzer_end_date, freq='M')
                        factor_df = pd.DataFrame()

                        progress_bar = st.progress(0)
                        for i, date in enumerate(dates):
                            date_str = date.strftime('%Y%m%d')
                            # å‘å‰å›æº¯60å¤©ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—å› å­
                            start_date_str_calc = (date - pd.Timedelta(days=60)).strftime('%Y%m%d')

                            raw_values = {}
                            for code in analyzer_stock_codes:
                                calc_func = getattr(factor_factory, f"calc_{factor_to_analyze}")
                                # å› å­å‡½æ•°éœ€è¦ä¸åŒçš„å‚æ•°ï¼Œè¿™é‡Œåšä¸€ä¸ªé€‚é…
                                if factor_to_analyze in ['momentum', 'volatility', 'net_inflow_ratio', 'north_hold_change']:
                                    raw_values[code] = calc_func(ts_code=code, start_date=start_date_str_calc, end_date=date_str)
                                else: # åŸºæœ¬é¢ç­‰å› å­
                                    raw_values[code] = calc_func(ts_code=code, date=date_str)

                            factor_df[date] = pd.Series(raw_values)
                            progress_bar.progress((i + 1) / len(dates))

                        factor_df = factor_df.T.dropna(how='all')
                        factor_df.index.name = 'trade_date'
                        st.success("å› å­æ•°æ®è®¡ç®—å®Œæˆï¼")
                        st.dataframe(factor_df.head())

                        # 2. è®¡ç®—ICå’ŒIR
                        st.info("æ­¥éª¤2: è®¡ç®—ä¿¡æ¯ç³»æ•° (IC) å’Œä¿¡æ¯æ¯”ç‡ (IR)...")
                        ic_values = {}
                        for date, factor_slice in factor_df.iterrows():
                            ic, p_val = factor_analyzer.calculate_ic(factor_slice.dropna())
                            if not np.isnan(ic):
                                ic_values[date] = ic

                        ic_series = pd.Series(ic_values)
                        ir = factor_analyzer.calculate_ir(ic_series)

                        ic_cols = st.columns(2)
                        ic_cols[0].metric("ICå‡å€¼ (Mean IC)", f"{ic_series.mean():.4f}")
                        ic_cols[1].metric("ä¿¡æ¯æ¯”ç‡ (IR)", f"{ir:.4f}")

                        st.markdown("##### IC æ—¶é—´åºåˆ—")
                        st.line_chart(ic_series)
                        st.success("IC/IR åˆ†æå®Œæˆï¼")

                        # 3. æ‰§è¡Œåˆ†å±‚å›æµ‹
                        st.info("æ­¥éª¤3: æ‰§è¡Œå› å­åˆ†å±‚å›æµ‹...")
                        layered_results, fig = factor_analyzer.run_layered_backtest(factor_df, num_quantiles=5, forward_return_period=20)
                        st.success("åˆ†å±‚å›æµ‹å®Œæˆï¼")

                        st.markdown("##### åˆ†å±‚å›æµ‹å‡€å€¼æ›²çº¿")
                        st.plotly_chart(fig, use_container_width=True)

                    except Exception as e:
                        st.error(f"å› å­åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        st.exception(e)

# --- 7. å›æµ‹å®éªŒå®¤ (é‡æ„ç‰ˆ) ---
if tab_backtest:
    with tab_backtest:
        st.subheader("ç­–ç•¥å›æµ‹å®éªŒå®¤")

        backtest_type = st.radio("é€‰æ‹©å›æµ‹ç±»å‹:", ("å‘é‡åŒ–å›æµ‹ (é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤šå› å­)", "äº‹ä»¶é©±åŠ¨å›æµ‹ (ç²¾åº¦é«˜ï¼Œæ¨¡æ‹ŸçœŸå®äº¤æ˜“)"))

    if backtest_type == "å‘é‡åŒ–å›æµ‹ (é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤šå› å­)":
        st.markdown("---")
        st.markdown("æ„å»ºå¤šå› å­ç­–ç•¥ï¼Œé€šè¿‡æŠ•èµ„ç»„åˆä¼˜åŒ–å™¨ç”Ÿæˆæƒé‡ï¼Œå¹¶åœ¨è€ƒè™‘äº¤æ˜“æˆæœ¬å’Œé£æ§è§„åˆ™ä¸‹è¿›è¡Œå›æµ‹ã€‚")

        st.markdown("#### 1. é€‰æ‹©ç­–ç•¥æ¨¡å‹")

        # V2.2 æ ¸å¿ƒå‡çº§ï¼šå¢åŠ ç­–ç•¥é€‰æ‹©
        strategy_model = st.radio(
            "é€‰æ‹©ç­–ç•¥æ¨¡å‹:",
            ["å›ºå®šæƒé‡å¤šå› å­", "è‡ªé€‚åº”æƒé‡ (IC-IR)", "æœºå™¨å­¦ä¹  (LGBM)"],
            horizontal=True,
            help="""
            - **å›ºå®šæƒé‡å¤šå› å­**: æ‰‹åŠ¨ä¸ºå¤šä¸ªå› å­è®¾å®šå›ºå®šæƒé‡ï¼Œæ„å»ºä¸€ä¸ªé™æ€çš„é€‰è‚¡æ¨¡å‹ã€‚
            - **è‡ªé€‚åº”æƒé‡ (IC-IR)**: ç³»ç»Ÿä¼šåŠ¨æ€è®¡ç®—æ¯ä¸ªå› å­åœ¨è¿‡å»çš„è¡¨ç°ï¼ˆICIRï¼‰ï¼Œå¹¶è‡ªåŠ¨ä¸ºè¡¨ç°å¥½çš„å› å­åˆ†é…æ›´é«˜çš„æƒé‡ï¼Œå®ç°æ¨¡å‹çš„åŠ¨æ€æ‹©ä¼˜ã€‚
            """
        )

        st.markdown("#### 2. é…ç½®å› å­ä¸å‚æ•°")

        # --- ç­–ç•¥å‚æ•°é…ç½®åŒº ---
        if strategy_model == "å›ºå®šæƒé‡å¤šå› å­":
            st.markdown("##### (A) æ‰‹åŠ¨è®¾ç½®å›ºå®šæƒé‡")
            factor_weights = {}
            factor_weights['momentum'] = st.slider("åŠ¨é‡å› å­ (Momentum) æƒé‡:", -1.0, 1.0, 0.5, 0.1)
            factor_weights['volatility'] = st.slider("ä½æ³¢åŠ¨å› å­ (Volatility) æƒé‡:", -1.0, 1.0, -0.3, 0.1) # æƒé‡ä¸ºè´Ÿä»£è¡¨é€‰å–æ³¢åŠ¨ç‡ä½çš„
            factor_weights['net_inflow_ratio'] = st.slider("èµ„é‡‘æµå…¥å› å­ (Net Inflow) æƒé‡:", -1.0, 1.0, 0.2, 0.1)

        elif strategy_model == "è‡ªé€‚åº”æƒé‡ (IC-IR)":
            st.markdown("##### (A) é€‰æ‹©å› å­æ± å¹¶é…ç½®è‡ªé€‚åº”å‚æ•°")
            factors_to_use_adaptive = st.multiselect(
                "é€‰æ‹©çº³å…¥è‡ªé€‚åº”æƒé‡æ¨¡å‹çš„å› å­æ± :",
                options=['momentum', 'volatility', 'net_inflow_ratio', 'roe', 'pe_ttm', 'growth_revenue_yoy'],
                default=['momentum', 'pe_ttm', 'roe']
            )
            ic_lookback_days = st.slider("IC/IR è®¡ç®—å›çœ‹æœŸ (å¤©):", 30, 365, 180, 10)

        st.markdown("#### 3. é…ç½®å›æµ‹å‚æ•°")
        col1, col2, col3 = st.columns(3)
        with col1:
            bt_start_date = st.date_input("å›æµ‹å¼€å§‹æ—¥æœŸ", datetime(2023, 1, 1), key="bt_start")
        with col2:
            bt_end_date = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", datetime.now() - timedelta(days=1), key="bt_end")
        with col3:
            rebalance_freq = st.selectbox("è°ƒä»“é¢‘ç‡", ['M', 'W'], index=0, help="M=æœˆåº¦è°ƒä»“, W=å‘¨åº¦è°ƒä»“")

        st.markdown("#### 4. é…ç½®äº¤æ˜“ä¸é£æ§è§„åˆ™")
        col4, col5, col6 = st.columns(3)
        with col4:
            commission = st.number_input("æ‰‹ç»­è´¹ç‡(%)", 0.0, 1.0, 0.03, 0.01) / 100
        with col5:
            max_weight = st.number_input("å•ç¥¨æœ€å¤§æƒé‡(%)", 1.0, 100.0, 10.0, 1.0) / 100
        with col6:
            stop_loss = st.number_input("æ­¢æŸçº¿(%)", 0.0, 50.0, 15.0, 1.0, help="0è¡¨ç¤ºä¸æ­¢æŸ") / 100
            stop_loss = stop_loss if stop_loss > 0 else None

        if st.button("ğŸš€ å¼€å§‹ä¼˜åŒ–å¹¶å›æµ‹"):
            with st.spinner("æ­£åœ¨æ‰§è¡Œå‘é‡åŒ–å›æµ‹..."):
                try:
                    # --- 1. æ•°æ®å‡†å¤‡ ---
                    st.info("æ­¥éª¤1: å‡†å¤‡è‚¡ç¥¨æ± å’Œä»·æ ¼æ•°æ®...")
                    stock_pool = get_stock_list()['ts_code'].tolist()[:100] # ç¼©å°èŒƒå›´ä»¥æé«˜é€Ÿåº¦
                    bt_start_str = bt_start_date.strftime('%Y%m%d')
                    bt_end_str = bt_end_date.strftime('%Y%m%d')

                    # ä¸ºè‡ªé€‚åº”ç­–ç•¥é¢„åŠ è½½æ›´é•¿å‘¨æœŸçš„ä»·æ ¼æ•°æ®
                    prices_start_str = bt_start_str
                    if strategy_model == "è‡ªé€‚åº”æƒé‡ (IC-IR)":
                        prices_start_str = (bt_start_date - timedelta(days=ic_lookback_days + 60)).strftime('%Y%m%d')

                    prices_dict = data_manager.run_batch_download(stock_pool, prices_start_str, bt_end_str)

                    all_prices_df = pd.DataFrame({
                        stock: df.set_index('trade_date')['close']
                        for stock, df in prices_dict.items() if df is not None and not df.empty
                    }).sort_index()
                    all_prices_df.index = pd.to_datetime(all_prices_df.index)
                    all_prices_df.dropna(axis=1, how='all', inplace=True)
                    stock_pool = all_prices_df.columns.tolist() # æ›´æ–°ä¸ºå®é™…æœ‰æ•°æ®çš„è‚¡ç¥¨æ± 
                    st.success(f"ä»·æ ¼æ•°æ®å‡†å¤‡å®Œæˆï¼è‚¡ç¥¨æ± æ•°é‡: {len(stock_pool)}")

                    # --- 2. ç¡®å®šè°ƒä»“æ—¥æœŸ ---
                    st.info("æ­¥éª¤2: ç¡®å®šè°ƒä»“æ—¥æœŸ...")
                    # ç­›é€‰å‡ºå›æµ‹åŒºé—´å†…çš„ä»·æ ¼æ•°æ®
                    backtest_prices = all_prices_df.loc[bt_start_date:bt_end_date]
                    if rebalance_freq == 'M':
                        rebalance_dates = backtest_prices.resample('M').last().index
                    else: # 'W'
                        rebalance_dates = backtest_prices.resample('W').last().index
                    rebalance_dates = rebalance_dates[(rebalance_dates >= backtest_prices.index.min()) & (rebalance_dates <= backtest_prices.index.max())]
                    st.success(f"ç¡®å®šäº† {len(rebalance_dates)} ä¸ªè°ƒä»“æ—¥ã€‚")

                    # --- 3. æ ¹æ®ç­–ç•¥é€‰æ‹©ï¼Œåˆå§‹åŒ–å¹¶æ‰§è¡Œæƒé‡ç”Ÿæˆ ---
                    st.info("æ­¥éª¤3: åœ¨æ¯ä¸ªè°ƒä»“æ—¥å¾ªç¯è®¡ç®—å› å­å’Œä¼˜åŒ–æƒé‡...")
                    all_weights_df = pd.DataFrame(index=backtest_prices.index, columns=stock_pool)
                    progress_bar = st.progress(0)
                    optimized_weights = pd.DataFrame() # Initialize to avoid UnboundLocalError

                    # --- A. å›ºå®šæƒé‡ç­–ç•¥ ---
                    if strategy_model == "å›ºå®šæƒé‡å¤šå› å­":
                        for i, date in enumerate(rebalance_dates):
                            composite_factor = pd.Series(dtype=float)
                            factor_date_str = date.strftime('%Y%m%d')
                            factor_start_str = (date - timedelta(days=60)).strftime('%Y%m%d')
                            for factor_name, weight in factor_weights.items():
                                if weight == 0: continue
                                raw_values = {s: factor_factory.calculate(factor_name, ts_code=s, start_date=factor_start_str, end_date=factor_date_str) for s in stock_pool}
                                raw_series = pd.Series(raw_values).dropna()
                                if raw_series.empty: continue
                                processed_factor = factor_processor.process_factor(raw_series, neutralize=True)
                                if composite_factor.empty:
                                    composite_factor = processed_factor.mul(weight).reindex(stock_pool).fillna(0)
                                else:
                                    composite_factor = composite_factor.add(processed_factor.mul(weight), fill_value=0)

                            if composite_factor.empty or composite_factor.sum() == 0: continue
                            selected_stocks = composite_factor.nlargest(20).index
                            cov_matrix = all_prices_df[selected_stocks].loc[:date].pct_change().iloc[-252:].cov() * 252
                            expected_returns = composite_factor[selected_stocks]
                            optimizer = quant_engine.PortfolioOptimizer(expected_returns, cov_matrix)
                            optimized_weights = optimizer.optimize_max_sharpe(max_weight_per_stock=max_weight)
                            all_weights_df.loc[date] = optimized_weights['weight']
                            progress_bar.progress((i + 1) / len(rebalance_dates))

                    # --- B. è‡ªé€‚åº”æƒé‡ç­–ç•¥ ---
                    elif strategy_model == "è‡ªé€‚åº”æƒé‡ (IC-IR)":
                        st.info("  æ­£åœ¨åˆå§‹åŒ–è‡ªé€‚åº”Alphaç­–ç•¥å¼•æ“...")
                        adaptive_strategy = quant_engine.AdaptiveAlphaStrategy(factor_factory, factor_processor, factor_analyzer, all_prices_df)
                        st.success("  è‡ªé€‚åº”ç­–ç•¥å¼•æ“åˆå§‹åŒ–æˆåŠŸï¼")

                        for i, date in enumerate(rebalance_dates):
                            composite_factor, dynamic_weights = adaptive_strategy.generate_composite_factor(date, stock_pool, tuple(factors_to_use_adaptive), ic_lookback_days)
                            if i == 0:
                                st.write("ç¬¬ä¸€æ¬¡è°ƒä»“æ—¥è®¡ç®—å‡ºçš„åŠ¨æ€å› å­æƒé‡:")
                                st.dataframe(dynamic_weights)

                            if composite_factor.empty or composite_factor.sum() == 0: continue
                            selected_stocks = composite_factor.nlargest(20).index
                            cov_matrix = all_prices_df[selected_stocks].loc[:date].pct_change().iloc[-252:].cov() * 252
                            expected_returns = composite_factor[selected_stocks]
                            optimizer = quant_engine.PortfolioOptimizer(expected_returns, cov_matrix)
                            optimized_weights = optimizer.optimize_max_sharpe(max_weight_per_stock=max_weight)
                            all_weights_df.loc[date] = optimized_weights['weight']
                            progress_bar.progress((i + 1) / len(rebalance_dates))

                    # --- C. æœºå™¨å­¦ä¹ ç­–ç•¥ ---
                    elif strategy_model == "æœºå™¨å­¦ä¹  (LGBM)":
                        st.info("  æ­£åœ¨åˆå§‹åŒ–å¹¶åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹...")
                        ml_strategy = quant_engine.MLAlphaStrategy()
                        model_loaded = ml_strategy.load_model() # é»˜è®¤åŠ è½½ ml_model.pkl

                        if not model_loaded:
                            st.error("é”™è¯¯ï¼šæ‰¾ä¸åˆ°å·²è®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶ (ml_model.pkl)ã€‚è¯·å…ˆåœ¨â€œæ¨¡å‹è®­ç»ƒå®¤â€ä¸­è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹ã€‚")
                            st.stop()
                        st.success("  æ¨¡å‹åŠ è½½æˆåŠŸï¼")

                        # è·å–æ¨¡å‹éœ€è¦çš„æ‰€æœ‰å› å­
                        model_features = ml_strategy.model.feature_name_

                        for i, date in enumerate(rebalance_dates):
                            date_str = date.strftime('%Y-%m-%d')
                            query = text(f"""
                                SELECT ts_code, factor_name, factor_value
                                FROM factors_exposure
                                WHERE trade_date = '{date_str}'
                                AND factor_name IN ({','.join([f"'{f}'" for f in model_features])})
                            """)
                            with data_manager.engine.connect() as conn:
                                factor_data_today = pd.read_sql(query, conn)

                            if factor_data_today.empty:
                                continue

                            factor_snapshot = factor_data_today.pivot(
                                index='ts_code', columns='factor_name', values='factor_value'
                            ).reindex(columns=model_features).dropna()

                            if factor_snapshot.empty:
                                continue

                            selected_stocks = ml_strategy.predict_top_stocks(factor_snapshot, top_n=20)

                            if len(selected_stocks) > 0:
                                weights = 1.0 / len(selected_stocks)
                                optimized_weights = pd.DataFrame({'weight': weights}, index=selected_stocks)
                                all_weights_df.loc[date] = optimized_weights['weight']

                            progress_bar.progress((i + 1) / len(rebalance_dates))

                    # --- 4. å¡«å……æƒé‡å¹¶æ‰§è¡Œå›æµ‹ ---
                    st.info("æ­¥éª¤4: æ‰€æœ‰è°ƒä»“æ—¥æƒé‡è®¡ç®—å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œå‘é‡åŒ–å›æµ‹...")
                    all_weights_df.fillna(0, inplace=True)
                    all_weights_df = all_weights_df.reindex(backtest_prices.index).ffill().fillna(0)
                    st.success("æƒé‡å¡«å……å®Œæ¯•ï¼")

                    st.info("æ­¥éª¤5: æ‰§è¡Œç»Ÿä¸€çš„å‘é‡åŒ–å›æµ‹...")
                    bt = quant_engine.VectorizedBacktester(
                        all_prices=all_prices_df,
                        all_factors=None,
                        rebalance_freq=rebalance_freq,
                        commission=commission,
                        slippage=0.0,
                        stop_loss_pct=stop_loss
                    )

                    results = bt.run(weights_df=all_weights_df)

                    st.success("å›æµ‹å®Œæˆï¼")
                    st.markdown("#### ç»©æ•ˆæŒ‡æ ‡ (å·²è€ƒè™‘äº¤æ˜“æˆæœ¬ä¸é£æ§)")
                    st.table(results['performance'])
                    if not optimized_weights.empty:
                        st.markdown("#### ä¼˜åŒ–åæŒä»“æƒé‡ (æœ€åè°ƒä»“æ—¥)")
                        st.dataframe(optimized_weights.style.format({'weight': '{:.2%}'}))
                    st.markdown("#### å‡€å€¼æ›²çº¿ä¸å›æ’¤")
                    st.plotly_chart(bt.plot_results(), use_container_width=True)

                    st.markdown("#### æŠ•èµ„ç»„åˆé£é™©æš´éœ²åˆ†æ")
                    with st.spinner("æ­£åœ¨æ‰§è¡Œé£é™©æš´éœ²åˆ†æ..."):
                        try:
                            risk_manager = quant_engine.RiskManager(factor_factory, factor_processor)
                            valid_rebalance_dates = all_weights_df[all_weights_df.sum(axis=1) > 0].index
                            all_exposures = []
                            for date in valid_rebalance_dates:
                                portfolio_weights = all_weights_df.loc[date].dropna()
                                portfolio_weights = portfolio_weights[portfolio_weights > 0]
                                if not portfolio_weights.empty:
                                    exposure = risk_manager.calculate_risk_exposure(portfolio_weights, date.strftime('%Y%m%d'))
                                    exposure.name = date
                                    all_exposures.append(exposure)
                            
                            if all_exposures:
                                exposure_df = pd.concat(all_exposures, axis=1).T
                                fig = go.Figure()
                                for factor in exposure_df.columns:
                                    fig.add_trace(go.Scatter(x=exposure_df.index, y=exposure_df[factor], mode='lines', name=factor))
                                fig.add_hline(y=0, line_dash="dash", line_color="white")
                                fig.update_layout(title="ç­–ç•¥é£é™©å› å­æš´éœ²åº¦æ—¶åºå›¾", xaxis_title="æ—¥æœŸ", yaxis_title="æ ‡å‡†åŒ–æš´éœ²å€¼ (Z-Score)", template="plotly_dark", height=500)
                                st.plotly_chart(fig, use_container_width=True)
                                st.caption("æš´éœ²å€¼ä¸ºæ­£ï¼Œè¡¨ç¤ºæ‚¨çš„æŠ•èµ„ç»„åˆåœ¨è¯¥é£é™©å› å­ä¸Šå‘ˆæ­£å‘æš´éœ²ï¼›å€¼ä¸ºè´Ÿåˆ™ç›¸åã€‚æ¥è¿‘0è¡¨ç¤ºåœ¨è¯¥é£é™©ä¸Šè¡¨ç°ä¸­æ€§ã€‚")
                            else:
                                st.warning("æœªèƒ½è®¡ç®—ä»»ä½•æ—¥æœŸçš„é£é™©æš´éœ²ã€‚")
                        except Exception as e:
                            st.error(f"é£é™©æš´éœ²åˆ†æå¤±è´¥: {e}")

                    st.markdown("#### æ·±åº¦ç»©æ•ˆå½’å›  (Brinson Model)")
                    with st.spinner("æ­£åœ¨æ‰§è¡ŒBrinsonå½’å› åˆ†æ..."):
                        try:
                            rebalance_dates_attr = bt._get_rebalance_dates()
                            if len(rebalance_dates_attr) > 1 and not optimized_weights.empty:
                                attribution_period_start = rebalance_dates_attr[0]
                                attribution_period_end = rebalance_dates_attr[-1]
                                stock_basics = get_stock_list()
                                stock_industry_map = stock_basics[stock_basics['ts_code'].isin(stock_pool)][['ts_code', 'industry']]
                                portfolio_weights_for_attr = optimized_weights['weight']
                                benchmark_weights_for_attr = pd.Series(1/len(stock_pool), index=stock_pool)
                                period_returns = all_prices_df.loc[attribution_period_end] / all_prices_df.loc[attribution_period_start] - 1

                                attribution_analyzer = quant_engine.PerformanceAttribution(
                                    portfolio_returns=period_returns.reindex(portfolio_weights_for_attr.index).fillna(0),
                                    portfolio_weights=portfolio_weights_for_attr,
                                    benchmark_returns=period_returns.reindex(benchmark_weights_for_attr.index).fillna(0),
                                    benchmark_weights=benchmark_weights_for_attr,
                                    stock_industry_map=stock_industry_map
                                )
                                attribution_results = attribution_analyzer.run_brinson_attribution()
                                st.dataframe(attribution_results)
                                st.caption("æ­£å‘çš„'èµ„äº§é…ç½®'è¡¨ç¤ºç­–ç•¥è¶…é…äº†è¡¨ç°ä¼˜äºåŸºå‡†çš„è¡Œä¸šã€‚æ­£å‘çš„'ä¸ªè‚¡é€‰æ‹©'è¡¨ç¤ºåœ¨è¡Œä¸šå†…éƒ¨é€‰å‡ºçš„ä¸ªè‚¡è¡¨ç°ä¼˜äºè¯¥è¡Œä¸šçš„æ•´ä½“åŸºå‡†ã€‚")
                            else:
                                st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œä¸šç»©å½’å› åˆ†æã€‚")
                        except Exception as e:
                            st.error(f"ä¸šç»©å½’å› åˆ†æå¤±è´¥: {e}")

                except Exception as e:
                    st.error(f"å‘é‡åŒ–å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                    st.exception(e)

    elif backtest_type == "äº‹ä»¶é©±åŠ¨å›æµ‹ (ç²¾åº¦é«˜ï¼Œæ¨¡æ‹ŸçœŸå®äº¤æ˜“)":
        st.markdown("---")
        st.markdown("æ¨¡æ‹ŸçœŸå®çš„é€æ—¥äº¤æ˜“è¿‡ç¨‹ï¼Œç­–ç•¥åœ¨æ¯ä¸ªäº¤æ˜“æ—¥æ¥æ”¶æ•°æ®å¹¶åšå‡ºå†³ç­–ï¼Œé€‚åˆéªŒè¯å‡çº¿ã€çªç ´ç­‰æ—¶åºå‹ç­–ç•¥ã€‚")

        st.markdown("#### 1. é…ç½®å›æµ‹å‚æ•°")
        ed_col1, ed_col2, ed_col3 = st.columns(3)
        with ed_col1:
            ed_start_date = st.date_input("å›æµ‹å¼€å§‹æ—¥æœŸ", datetime(2023, 1, 1), key="ed_start")
        with ed_col2:
            ed_end_date = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", datetime.now() - timedelta(days=1), key="ed_end")
        with ed_col3:
            initial_capital = st.number_input("åˆå§‹èµ„é‡‘", 100000, 100000000, 1000000, 100000)

        st.markdown("#### 2. é…ç½®ç­–ç•¥ä¸è‚¡ç¥¨æ± ")
        strategy_choice = st.selectbox("é€‰æ‹©ç­–ç•¥", ["åŒå‡çº¿äº¤å‰ç­–ç•¥"])

        ed_col4, ed_col5 = st.columns(2)
        with ed_col4:
            short_window = st.slider("çŸ­æœŸå‡çº¿çª—å£", 5, 50, 10, 1)
        with ed_col5:
            long_window = st.slider("é•¿æœŸå‡çº¿çª—å£", 20, 120, 30, 1)

        stock_pool_options = get_stock_list()['ts_code'] + " " + get_stock_list()['name']
        ed_stock_pool = st.multiselect("é€‰æ‹©è‚¡ç¥¨æ±  (å»ºè®®3-5æ”¯)", options=stock_pool_options, default=[s for s in stock_pool_options if "èŒ…å°" in s or "å¹³å®‰" in s])
        ed_stock_codes = [s.split(" ")[0] for s in ed_stock_pool]

        if st.button("ğŸš€ å¼€å§‹äº‹ä»¶é©±åŠ¨å›æµ‹"):
            if not ed_stock_codes:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ”¯è‚¡ç¥¨ã€‚")
            else:
                with st.spinner("æ­£åœ¨æ‰§è¡Œäº‹ä»¶é©±åŠ¨å›æµ‹ï¼Œè¯·ç¨å€™..."):
                    try:
                        # 1. æ•°æ®å‡†å¤‡
                        st.info("æ­¥éª¤1: å‡†å¤‡è‚¡ç¥¨æ± çš„ä»·æ ¼ä¸æˆäº¤é‡æ•°æ®...")
                        ed_start_str = ed_start_date.strftime('%Y%m%d')
                        ed_end_str = ed_end_date.strftime('%Y%m%d')
                        prices_dict = data_manager.run_batch_download(ed_stock_codes, ed_start_str, ed_end_str)

                        all_prices_df = pd.DataFrame({
                            stock: df.set_index('trade_date')['close']
                            for stock, df in prices_dict.items() if df is not None and not df.empty and 'close' in df.columns
                        }).sort_index()

                        all_volumes_df = pd.DataFrame({
                            stock: df.set_index('trade_date')['vol']
                            for stock, df in prices_dict.items() if df is not None and not df.empty and 'vol' in df.columns
                        }).sort_index()

                        common_index = all_prices_df.index.intersection(all_volumes_df.index)
                        common_columns = all_prices_df.columns.intersection(all_volumes_df.columns)
                        all_prices_df = all_prices_df.loc[common_index, common_columns]
                        all_volumes_df = all_volumes_df.loc[common_index, common_columns]
                        all_prices_df.dropna(axis=1, how='all', inplace=True)
                        all_volumes_df = all_volumes_df.reindex(columns=all_prices_df.columns)

                        st.success(f"ä»·æ ¼ä¸æˆäº¤é‡æ•°æ®å‡†å¤‡å®Œæˆï¼è‚¡ç¥¨æ± : {all_prices_df.columns.tolist()}")

                        # 2. åˆå§‹åŒ–äº‹ä»¶é©±åŠ¨å¼•æ“
                        st.info("æ­¥éª¤2: åˆå§‹åŒ–äº‹ä»¶é©±åŠ¨å¼•æ“ç»„ä»¶...")
                        from queue import Queue
                        events_queue = Queue()

                        data_handler = quant_engine.SimpleDataHandler(events_queue, all_prices_df, all_volumes_df)
                        portfolio = quant_engine.SimplePortfolio(data_handler, events_queue, initial_capital)
                        strategy = quant_engine.SimpleMovingAverageStrategy(data_handler, short_window, long_window)
                        execution_handler = quant_engine.MockExecutionHandler(events_queue, data_handler, portfolio)

                        backtester = quant_engine.EventDrivenBacktester(
                            data_handler, strategy, portfolio, execution_handler
                        )
                        st.success("å¼•æ“åˆå§‹åŒ–å®Œæ¯•ï¼")

                        # 3. è¿è¡Œå›æµ‹
                        st.info("æ­¥éª¤3: å¼€å§‹è¿è¡Œäº‹ä»¶å¾ªç¯...")
                        ed_results = backtester.run_backtest()
                        st.success("äº‹ä»¶é©±åŠ¨å›æµ‹å®Œæˆï¼")

                        # 4. å±•ç¤ºç»“æœ
                        st.markdown("#### ç»©æ•ˆæŒ‡æ ‡")
                        st.table(ed_results['performance'])

                        st.markdown("#### å‡€å€¼æ›²çº¿")
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(x=ed_results['equity_curve'].index, y=ed_results['equity_curve']['total'], mode='lines', name='ç­–ç•¥å‡€å€¼'))
                        fig.update_layout(title="äº‹ä»¶é©±åŠ¨å›æµ‹ - èµ„äº§å‡€å€¼å˜åŒ–", template="plotly_dark", height=500)
                        st.plotly_chart(fig, use_container_width=True)

                        st.markdown("#### è¯¦ç»†äº¤æ˜“è®°å½•")
                        st.dataframe(ed_results['trade_log'], use_container_width=True)

                    except Exception as e:
                        st.error(f"äº‹ä»¶é©±åŠ¨å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        st.exception(e)

# --- V2.3 æ–°å¢: 9. æ¨¡å‹è®­ç»ƒå®¤ ---
if tab_trainer:
    with tab_trainer:
        st.subheader("ğŸ”¬ æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå®¤")
        st.markdown("åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥é€‰æ‹©å› å­ï¼ˆç‰¹å¾ï¼‰å’Œé¢„æµ‹ç›®æ ‡ï¼Œè®­ç»ƒæ‚¨è‡ªå·±çš„æœºå™¨å­¦ä¹ é€‰è‚¡æ¨¡å‹ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å›æµ‹å®éªŒå®¤ä¸­ã€‚")

        st.markdown("#### 1. é…ç½®è®­ç»ƒå‚æ•°")

        train_cols = st.columns(3)
        with train_cols[0]:
            train_start_date = st.date_input("è®­ç»ƒå¼€å§‹æ—¥æœŸ", datetime(2023, 1, 1), key="train_start")
        with train_cols[1]:
            train_end_date = st.date_input("è®­ç»ƒç»“æŸæ—¥æœŸ", datetime(2024, 12, 31), key="train_end")
        with train_cols[2]:
            forward_period = st.number_input("é¢„æµ‹å‘¨æœŸ(å¤©)", 1, 60, 20, 1)

        try:
            with data_manager.engine.connect() as conn:
                all_db_factors = pd.read_sql("SELECT DISTINCT factor_name FROM factors_exposure", conn)['factor_name'].tolist()
        except Exception:
            all_db_factors = ['momentum', 'roe', 'pe_ttm', 'volatility', 'net_inflow_ratio']

        # ã€é²æ£’æ€§ä¿®å¤ã€‘ç¡®ä¿é»˜è®¤å€¼æ˜¯å¯ç”¨é€‰é¡¹çš„å­é›†ï¼Œé˜²æ­¢å› æ•°æ®åº“ä¸ºç©ºæˆ–å› å­ä¸åŒ¹é…è€ŒæŠ¥é”™
        desired_defaults = ['momentum', 'roe', 'pe_ttm', 'volatility']
        actual_defaults = [f for f in desired_defaults if f in all_db_factors]

        selected_features = st.multiselect(
            "é€‰æ‹©ç”¨ä½œç‰¹å¾çš„å› å­:",
            options=all_db_factors,
            default=actual_defaults
        )

        st.markdown("#### 2. å¼€å§‹è®­ç»ƒ")
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", use_container_width=True):
            if not selected_features:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å› å­ã€‚")
            else:
                with st.spinner("æ­£åœ¨æ‰§è¡Œæ¨¡å‹è®­ç»ƒå·¥ä½œæµï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´..."):
                    try:
                        # --- 1. æ•°æ®å‡†å¤‡ ---
                        st.info("æ­¥éª¤1: å‡†å¤‡è‚¡ç¥¨æ± å’Œä»·æ ¼æ•°æ®...")
                        stock_pool = get_stock_list()['ts_code'].tolist()[:200]
                        train_start_str = train_start_date.strftime('%Y%m%d')
                        train_end_fetch_str = (train_end_date + timedelta(days=forward_period * 2)).strftime('%Y%m%d')

                        prices_dict = data_manager.run_batch_download(stock_pool, train_start_str, train_end_fetch_str)
                        all_prices_df = pd.DataFrame({
                            stock: df.set_index('trade_date')['close']
                            for stock, df in prices_dict.items() if df is not None and not df.empty
                        }).sort_index()
                        all_prices_df.index = pd.to_datetime(all_prices_df.index)
                        all_prices_df.dropna(axis=1, how='all', inplace=True)
                        st.success(f"ä»·æ ¼æ•°æ®å‡†å¤‡å®Œæˆï¼")

                        st.info("æ­¥éª¤2: å‡†å¤‡å› å­æ•°æ®...")
                        query = text(f"""
                            SELECT trade_date, ts_code, factor_name, factor_value
                            FROM factors_exposure
                            WHERE trade_date BETWEEN '{train_start_date.strftime('%Y-%m-%d')}' AND '{train_end_date.strftime('%Y-%m-%d')}'
                            AND factor_name IN ({','.join([f"'{f}'" for f in selected_features])})
                        """)
                        with data_manager.engine.connect() as conn:
                            all_factor_data = pd.read_sql(query, conn)

                        all_factor_data['trade_date'] = pd.to_datetime(all_factor_data['trade_date'])
                        st.success(f"å› å­æ•°æ®å‡†å¤‡å®Œæˆï¼")

                        # --- 2. æ¨¡å‹è®­ç»ƒ ---
                        st.info("æ­¥éª¤3: å®ä¾‹åŒ–å¹¶è®­ç»ƒæ¨¡å‹...")
                        ml_strategy = quant_engine.MLAlphaStrategy()
                        train_results = ml_strategy.train(all_prices_df, all_factor_data)
                        st.success("æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")

                        # --- 3. å±•ç¤ºç»“æœ ---
                        st.markdown("#### è®­ç»ƒç»“æœæŠ¥å‘Š")
                        st.metric("æµ‹è¯•é›†å‡†ç¡®ç‡", f"{train_results.get('accuracy', 0):.2%}")
                        st.json(train_results)

                    except Exception as e:
                        st.error(f"æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        st.exception(e)

# --- 10. ç³»ç»Ÿä»»åŠ¡ ---
if tab_tasks:
    with tab_tasks:
        st.subheader("è‡ªåŠ¨åŒ–ä¸ç›‘æ§ä¸­å¿ƒ")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### åå°ä»»åŠ¡æ‰‹åŠ¨è§¦å‘å™¨")
            st.warning("ã€é‡è¦ã€‘æ­¤ä»»åŠ¡è€—æ—¶è¾ƒé•¿ï¼ˆçº¦20-40åˆ†é’Ÿï¼‰ï¼Œå°†åœ¨åå°ç‹¬ç«‹è¿è¡Œã€‚æ‚¨å¯ä»¥åœ¨å³ä¾§çš„æ—¥å¿—ç›‘æ§é¢æ¿æŸ¥çœ‹è¿›åº¦ã€‚")

            if st.button("ğŸš€ æ‰§è¡Œæ¯æ—¥ç»Ÿä¸€æ•°æ®ç®¡é“ (æŠ½å–+è®¡ç®—)", help="å¯åŠ¨åå°è¿›ç¨‹ï¼Œæ‰§è¡Œå®Œæ•´çš„æ•°æ®æŠ½å–å’Œå› å­è®¡ç®—æµç¨‹ï¼Œå¹¶å°†ç»“æœå­˜å…¥æ•°æ®åº“ã€‚"):
                # FIX 2: Corrected the structure of the try/except block, completed the Popen statement,
                # and fixed the indentation for 'with col2' which was causing a syntax error.
                try:
                    command = [sys.executable, "run_daily_pipeline.py"]
                    # Popen starts a new process and does not block Streamlit.
                    # Completed the Popen call with a closing parenthesis.
                    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                    st.success(f"åå°ä»»åŠ¡å·²å¯åŠ¨ (è¿›ç¨‹ID: {process.pid})ã€‚")
                    st.info("æ‚¨å¯å…³é—­æ­¤æµè§ˆå™¨çª—å£ï¼Œä»»åŠ¡å°†åœ¨æœåŠ¡å™¨åå°ç»§ç»­è¿è¡Œã€‚")
                except FileNotFoundError:
                    st.error("é”™è¯¯: 'run_daily_pipeline.py' not found. è¯·ç¡®ä¿è¯¥æ–‡ä»¶ä¸app.pyåœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
                except Exception as e:
                    st.error(f"å¯åŠ¨åå°ä»»åŠ¡å¤±è´¥: {e}")

        # This 'with' block was incorrectly indented. It's now at the correct level.
        with col2:
            st.markdown("#### ç³»ç»ŸçŠ¶æ€ç›‘æ§é¢æ¿")
            st.info("å®æ—¶æ£€æŸ¥ç³»ç»Ÿå…³é”®ç»„ä»¶çš„è¿è¡ŒçŠ¶æ€ã€‚")

            if st.button("åˆ·æ–°ç›‘æ§çŠ¶æ€"):
                # 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
                try:
                    with data_manager.engine.connect() as connection:
                        connection.execute(text("SELECT 1"))
                    st.success("âœ… **æ•°æ®åº“è¿æ¥:** æ­£å¸¸")
                except Exception as e:
                    st.error(f"âŒ **æ•°æ®åº“è¿æ¥:** å¤±è´¥ - {e}")

                # 2. æŸ¥è¯¢Tushare APIç§¯åˆ†
                try:
                    df_score = data_manager.pro.query('tushare_score')
                    if df_score is not None and not df_score.empty:
                        score = df_score.iloc[0]['score']
                        st.success(f"âœ… **Tushare APIç§¯åˆ†:** {score} åˆ†")
                    else:
                         st.warning("âš ï¸ **Tushare APIç§¯åˆ†:** æœªèƒ½æŸ¥è¯¢åˆ°ç§¯åˆ†ä¿¡æ¯ã€‚")
                except Exception as e:
                    st.error(f"âŒ **Tushare APIç§¯åˆ†:** æŸ¥è¯¢å¤±è´¥ - {e}")

                # 3. æ˜¾ç¤ºæœ€æ–°æ—¥å¿—
                st.markdown("##### æœ€æ–°æ—¥å¿— (`quant_project.log`)")
                try:
                    with open('quant_project.log', 'r', encoding='utf-8') as f:
                        log_lines = f.readlines()
                    st.text_area("Log Preview:", "".join(log_lines[-20:]), height=300)
                except FileNotFoundError:
                    st.warning("âš ï¸ æ—¥å¿—æ–‡ä»¶ 'quant_project.log' æœªæ‰¾åˆ°ã€‚")
                except Exception as e:
                    st.error(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
