"""
Refactored system check with improved design patterns and maintainability
"""
import argparse
import asyncio
import json
import os
import sys
import time
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from enum import Enum
from abc import ABC, abstractmethod

import aiohttp
import pandas as pd
import psutil
from sqlalchemy import create_engine, text

# Add current directory to sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import project modules
try:
    import config
    import data
    import intelligence
    import quant_engine as qe
    from logger_config import log
except ImportError as e:
    print(f"FATAL: å…³é”®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‚¨åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼Œå¹¶ä¸”æ‰€æœ‰ä¾èµ–å·²å®‰è£…ã€‚")
    sys.exit(1)


class CheckMode(Enum):
    """System check modes"""
    QUICK = "quick"
    FULL = "full"
    STABILITY = "stability"
    PERFORMANCE = "performance"


@dataclass
class CheckResult:
    """Result of a system check"""
    name: str
    success: bool
    duration_seconds: float
    message: str = ""
    details: Dict[str, Any] = None
    error: Optional[Exception] = None
    
    def __post_init__(self):
        if self.details is None:
            self.details = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return {
            'name': self.name,
            'success': self.success,
            'duration_seconds': self.duration_seconds,
            'message': self.message,
            'details': self.details,
            'error': str(self.error) if self.error else None
        }


class SystemCheckConfig:
    """Centralized configuration for system checks"""
    
    # Performance thresholds
    SIMPLE_QUERY_MAX_MS = 100
    COMPLEX_QUERY_MAX_MS = 1000
    FACTOR_CALCULATION_MAX_MS = 5000
    
    # Resource thresholds
    MAX_CPU_PERCENT = 80
    MAX_MEMORY_PERCENT = 85
    MAX_DISK_PERCENT = 90
    
    # Data quality thresholds
    MIN_COVERAGE_RATIO = 0.9
    MAX_DATA_AGE_DAYS = 7
    MAX_INVALID_DATA_PERCENT = 1.0
    MAX_PRICE_INCONSISTENCY_PERCENT = 0.1
    MAX_FINANCIAL_DATA_AGE_MONTHS = 6
    MIN_ORPHAN_THRESHOLD = 100
    
    # Core tables
    CORE_TABLES = {
        'stock_basic': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯',
        'ts_daily': 'æ—¥çº¿è¡Œæƒ…æ•°æ®', 
        'factors_exposure': 'å› å­æš´éœ²æ•°æ®',
        'financial_indicators': 'è´¢åŠ¡æŒ‡æ ‡æ•°æ®',
        'ts_adj_factor': 'å¤æƒå› å­æ•°æ®'
    }
    
    TIME_RANGE_TABLES = ['ts_daily', 'factors_exposure', 'financial_indicators']
    
    # Test configuration
    TEST_STOCKS = ["600519.SH", "000001.SZ", "000002.SZ"]
    STABLE_FACTORS = ["pe_ttm", "pb"]
    MIN_FACTOR_SUCCESS_RATE = 0.6
    
    @classmethod
    def get_config(cls, profile: str = "default") -> 'SystemCheckConfig':
        """Get configuration by profile"""
        try:
            from system_check_config_improved import get_config
            return get_config(profile)
        except ImportError:
            log.warning("Advanced configuration not available, using basic configuration")
            return cls()


class BaseChecker(ABC):
    """Base class for all system checkers"""
    
    def __init__(self, dm: data.DataManager, config: SystemCheckConfig):
        self.dm = dm
        self.config = config
        self.results: List[CheckResult] = []
    
    @abstractmethod
    def run_checks(self) -> List[CheckResult]:
        """Run all checks and return results"""
        pass
    
    def _execute_check(self, check_name: str, check_func: Callable) -> CheckResult:
        """Execute a single check with timing and error handling"""
        start_time = time.time()
        
        try:
            success = check_func()
            duration = time.time() - start_time
            
            return CheckResult(
                name=check_name,
                success=bool(success),
                duration_seconds=duration,
                message="æ£€æŸ¥å®Œæˆ" if success else "æ£€æŸ¥å¤±è´¥"
            )
            
        except Exception as e:
            duration = time.time() - start_time
            log.error(f"æ£€æŸ¥ {check_name} å¤±è´¥: {e}")
            
            return CheckResult(
                name=check_name,
                success=False,
                duration_seconds=duration,
                message=str(e),
                error=e
            )


class DatabaseChecker(BaseChecker):
    """Enhanced database checker with improved design"""
    
    def __init__(self, dm: data.DataManager, config: SystemCheckConfig):
        super().__init__(dm, config)
        self.issues_found = []
        self.total_checks = 0
        self.passed_checks = 0
    
    def run_checks(self) -> List[CheckResult]:
        """Run comprehensive database checks"""
        log.info("  --- å¼€å§‹æ•°æ®åº“æ£€æŸ¥ ---")
        
        check_methods = [
            ("core_tables", "æ ¸å¿ƒè¡¨æ£€æŸ¥", self._check_core_tables),
            ("time_ranges", "æ—¶é—´èŒƒå›´æ£€æŸ¥", self._check_time_ranges),
            ("stock_consistency", "è‚¡ç¥¨ä¸€è‡´æ€§æ£€æŸ¥", self._check_stock_consistency),
            ("data_quality", "æ•°æ®è´¨é‡æ£€æŸ¥", self._check_data_quality),
            ("factor_completeness", "å› å­å®Œæ•´æ€§æ£€æŸ¥", self._check_factor_completeness),
            ("financial_completeness", "è´¢åŠ¡å®Œæ•´æ€§æ£€æŸ¥", self._check_financial_completeness),
            ("data_relationships", "æ•°æ®å…³è”æ€§æ£€æŸ¥", self._check_data_relationships),
            ("database_metrics", "æ•°æ®åº“æŒ‡æ ‡æ£€æŸ¥", self._check_database_metrics)
        ]
        
        try:
            with self.dm.engine.connect() as conn:
                for check_id, description, check_method in check_methods:
                    log.info(f"  æ‰§è¡Œ{description}")
                    result = self._execute_check(check_id, lambda: check_method(conn))
                    self.results.append(result)
                    
                    if result.success:
                        self.passed_checks += 1
                    else:
                        self.issues_found.append(f"{description}: {result.message}")
                    
                    self.total_checks += 1
            
            self._generate_report()
            return self.results
            
        except Exception as e:
            log.error(f"æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
            error_result = CheckResult(
                name="database_check",
                success=False,
                duration_seconds=0,
                message=str(e),
                error=e
            )
            return [error_result]
    
    def _check_core_tables(self, conn) -> bool:
        """Check core table existence and basic statistics"""
        try:
            for table, desc in self.config.CORE_TABLES.items():
                count = conn.execute(text(f"SELECT COUNT(*) FROM {table}")).scalar()
                log.info(f"    âœ“ {desc} ({table}): {count:,} æ¡è®°å½•")
            return True
        except Exception as e:
            log.error(f"    âœ— æ ¸å¿ƒè¡¨æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_time_ranges(self, conn) -> bool:
        """Check data time ranges and freshness"""
        try:
            for table in self.config.TIME_RANGE_TABLES:
                date_col = 'end_date' if table == 'financial_indicators' else 'trade_date'
                
                result = conn.execute(text(f"""
                    SELECT MIN({date_col}) as min_date, 
                           MAX({date_col}) as max_date,
                           COUNT(DISTINCT {date_col}) as date_count
                    FROM {table}
                """)).fetchone()
                
                if result and result[0]:
                    log.info(f"    âœ“ {table}: {result[0]} è‡³ {result[1]} ({result[2]} ä¸ªæ—¥æœŸ)")
                    
                    # Check data freshness
                    if table in ['ts_daily', 'factors_exposure']:
                        days_old = (datetime.now().date() - result[1]).days
                        if days_old > self.config.MAX_DATA_AGE_DAYS:
                            self.issues_found.append(f"{table} æ•°æ®è¿‡æ—§ï¼Œæœ€æ–°æ•°æ®è·ä»Š {days_old} å¤©")
                else:
                    log.warning(f"    âš  {table}: æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®")
                    self.issues_found.append(f"{table} æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®")
            
            return True
        except Exception as e:
            log.error(f"    âœ— æ—¶é—´èŒƒå›´æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_stock_consistency(self, conn) -> bool:
        """Check stock code consistency across tables"""
        try:
            stock_counts = {}
            for table in ['stock_basic', 'ts_daily', 'factors_exposure', 'financial_indicators']:
                if table == 'stock_basic':
                    count = conn.execute(text(f"SELECT COUNT(*) FROM {table}")).scalar()
                else:
                    count = conn.execute(text(f"SELECT COUNT(DISTINCT ts_code) FROM {table}")).scalar()
                stock_counts[table] = count
            
            log.info("    è‚¡ç¥¨ä»£ç æ•°é‡å¯¹æ¯”:")
            for table, count in stock_counts.items():
                log.info(f"      {table}: {count:,} åªè‚¡ç¥¨")
            
            # Check coverage ratios
            base_count = stock_counts.get('stock_basic', 0)
            if base_count > 0:
                for table, count in stock_counts.items():
                    if table != 'stock_basic':
                        coverage = count / base_count
                        if coverage < self.config.MIN_COVERAGE_RATIO:
                            self.issues_found.append(f"{table} è‚¡ç¥¨è¦†ç›–ç‡è¿‡ä½: {coverage:.1%}")
            
            return True
        except Exception as e:
            log.error(f"    âœ— è‚¡ç¥¨ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_data_quality(self, conn) -> bool:
        """Check data quality issues in trading data"""
        try:
            quality_issues = conn.execute(text("""
                SELECT 
                    COUNT(*) as total_records,
                    SUM(CASE WHEN close IS NULL OR close <= 0 THEN 1 ELSE 0 END) as invalid_close,
                    SUM(CASE WHEN vol IS NULL OR vol < 0 THEN 1 ELSE 0 END) as invalid_volume,
                    SUM(CASE WHEN high < low THEN 1 ELSE 0 END) as price_inconsistency
                FROM ts_daily
                WHERE trade_date >= (SELECT MAX(trade_date) - INTERVAL '30 days' FROM ts_daily)
            """)).fetchone()
            
            if quality_issues and quality_issues[0] > 0:
                total_records = quality_issues[0]
                invalid_close_pct = (quality_issues[1] / total_records) * 100
                price_inconsist_pct = (quality_issues[3] / total_records) * 100
                
                log.info(f"    æœ€è¿‘30å¤©æ•°æ®è´¨é‡ (å…±{total_records:,}æ¡):")
                log.info(f"      æ— æ•ˆæ”¶ç›˜ä»·: {quality_issues[1]} ({invalid_close_pct:.2f}%)")
                log.info(f"      ä»·æ ¼ä¸ä¸€è‡´: {quality_issues[3]} ({price_inconsist_pct:.2f}%)")
                
                if invalid_close_pct > self.config.MAX_INVALID_DATA_PERCENT:
                    self.issues_found.append(f"æ— æ•ˆæ”¶ç›˜ä»·æ¯”ä¾‹è¿‡é«˜: {invalid_close_pct:.2f}%")
                if price_inconsist_pct > self.config.MAX_PRICE_INCONSISTENCY_PERCENT:
                    self.issues_found.append(f"ä»·æ ¼ä¸ä¸€è‡´æ¯”ä¾‹è¿‡é«˜: {price_inconsist_pct:.2f}%")
            
            return True
        except Exception as e:
            log.error(f"    âœ— æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_factor_completeness(self, conn) -> bool:
        """Check factor data completeness"""
        try:
            factor_stats = conn.execute(text("""
                SELECT 
                    factor_name,
                    COUNT(*) as record_count,
                    COUNT(DISTINCT ts_code) as stock_count,
                    COUNT(DISTINCT trade_date) as date_count
                FROM factors_exposure 
                GROUP BY factor_name 
                ORDER BY record_count DESC
            """)).fetchall()
            
            if factor_stats:
                log.info(f"    å› å­æ•°æ®ç»Ÿè®¡ (å…±{len(factor_stats)}ä¸ªå› å­):")
                for factor in factor_stats[:5]:  # Show top 5
                    log.info(f"      {factor[0]}: {factor[1]:,}æ¡è®°å½•, {factor[2]}åªè‚¡ç¥¨")
            else:
                self.issues_found.append("æ— å› å­æ•°æ®")
            
            return True
        except Exception as e:
            log.error(f"    âœ— å› å­å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_financial_completeness(self, conn) -> bool:
        """Check financial data completeness"""
        try:
            financial_stats = conn.execute(text("""
                SELECT 
                    COUNT(DISTINCT ts_code) as stock_count,
                    COUNT(DISTINCT end_date) as period_count,
                    MIN(end_date) as earliest_period,
                    MAX(end_date) as latest_period,
                    COUNT(*) as total_records
                FROM financial_indicators
            """)).fetchone()
            
            if financial_stats:
                log.info("    è´¢åŠ¡æ•°æ®ç»Ÿè®¡:")
                log.info(f"      è¦†ç›–è‚¡ç¥¨: {financial_stats[0]:,} åª")
                log.info(f"      æŠ¥å‘ŠæœŸæ•°: {financial_stats[1]} ä¸ª")
                log.info(f"      æ€»è®°å½•æ•°: {financial_stats[4]:,} æ¡")
            else:
                self.issues_found.append("æ— è´¢åŠ¡æ•°æ®")
            
            return True
        except Exception as e:
            log.error(f"    âœ— è´¢åŠ¡å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_data_relationships(self, conn) -> bool:
        """Check data relationships between tables"""
        try:
            orphan_daily = conn.execute(text("""
                SELECT COUNT(DISTINCT d.ts_code) 
                FROM ts_daily d 
                LEFT JOIN factors_exposure f ON d.ts_code = f.ts_code AND d.trade_date = f.trade_date
                WHERE f.ts_code IS NULL 
                AND d.trade_date >= (SELECT MAX(trade_date) - INTERVAL '7 days' FROM ts_daily)
            """)).scalar()
            
            if orphan_daily and orphan_daily > 0:
                log.warning(f"    âš  å‘ç° {orphan_daily} åªè‚¡ç¥¨æœ‰æ—¥çº¿æ•°æ®ä½†ç¼ºå°‘å› å­æ•°æ®")
                if orphan_daily > self.config.MIN_ORPHAN_THRESHOLD:
                    self.issues_found.append(f"å¤§é‡è‚¡ç¥¨ç¼ºå°‘å› å­æ•°æ®: {orphan_daily} åª")
            else:
                log.info("    âœ“ æ•°æ®å…³è”æ€§è‰¯å¥½")
            
            return True
        except Exception as e:
            log.error(f"    âœ— æ•°æ®å…³è”æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _check_database_metrics(self, conn) -> bool:
        """Check database performance metrics"""
        try:
            db_size = conn.execute(text("""
                SELECT pg_size_pretty(pg_database_size(current_database()))
            """)).scalar()
            
            log.info(f"    æ•°æ®åº“å¤§å°: {db_size}")
            return True
        except Exception as e:
            log.error(f"    âœ— æ•°æ®åº“æŒ‡æ ‡æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _generate_report(self) -> None:
        """Generate comprehensive report"""
        log.info("  --- æ•°æ®åº“æ£€æŸ¥æŠ¥å‘Š ---")
        log.info(f"  æ€»æ£€æŸ¥é¡¹: {self.total_checks}")
        log.info(f"  é€šè¿‡æ£€æŸ¥: {self.passed_checks}")
        
        if self.total_checks > 0:
            success_rate = (self.passed_checks / self.total_checks) * 100
            log.info(f"  æ£€æŸ¥é€šè¿‡ç‡: {success_rate:.1f}%")
        
        if self.issues_found:
            log.warning(f"  å‘ç° {len(self.issues_found)} ä¸ªé—®é¢˜:")
            for i, issue in enumerate(self.issues_found, 1):
                log.warning(f"    {i}. {issue}")
        else:
            log.info("  âœ… æœªå‘ç°æ•°æ®å®Œæ•´æ€§é—®é¢˜")


class SystemResourceChecker(BaseChecker):
    """System resource checker"""
    
    def run_checks(self) -> List[CheckResult]:
        """Run system resource checks"""
        log.info("  --- å¼€å§‹ç³»ç»Ÿèµ„æºæ£€æŸ¥ ---")
        
        result = self._execute_check("system_resources", self._check_resources)
        return [result]
    
    def _check_resources(self) -> bool:
        """Check system resources"""
        try:
            # CPU usage
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # Memory usage
            memory = psutil.virtual_memory()
            
            # Disk usage
            disk = psutil.disk_usage('.')
            disk_percent = (disk.used / disk.total) * 100
            
            log.info(f"    CPUä½¿ç”¨ç‡: {cpu_percent}%")
            log.info(f"    å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
            log.info(f"    ç£ç›˜ä½¿ç”¨ç‡: {disk_percent:.1f}%")
            
            # Check thresholds
            is_healthy = (
                cpu_percent < self.config.MAX_CPU_PERCENT and
                memory.percent < self.config.MAX_MEMORY_PERCENT and
                disk_percent < self.config.MAX_DISK_PERCENT
            )
            
            if is_healthy:
                log.info("    âœ“ ç³»ç»Ÿèµ„æºçŠ¶æ€è‰¯å¥½")
            else:
                log.warning("    âš  ç³»ç»Ÿèµ„æºç´§å¼ ")
            
            return is_healthy
            
        except Exception as e:
            log.error(f"    âœ— ç³»ç»Ÿèµ„æºæ£€æŸ¥å¤±è´¥: {e}")
            return False


class SystemCheckOrchestrator:
    """Main orchestrator for system checks"""
    
    def __init__(self, dm: data.DataManager, mode: CheckMode = CheckMode.FULL):
        self.dm = dm
        self.mode = mode
        self.config = SystemCheckConfig.get_config()
        self.checkers: List[BaseChecker] = []
        self.all_results: List[CheckResult] = []
    
    def register_checkers(self) -> None:
        """Register all checkers based on mode"""
        # Always include database checker
        self.checkers.append(DatabaseChecker(self.dm, self.config))
        
        # Add resource checker for full and performance modes
        if self.mode in [CheckMode.FULL, CheckMode.PERFORMANCE]:
            self.checkers.append(SystemResourceChecker(self.dm, self.config))
    
    def run_all_checks(self) -> bool:
        """Run all registered checks"""
        log.info(f"=== ç³»ç»Ÿæ£€æŸ¥ ({self.mode.value.upper()}) ===")
        
        self.register_checkers()
        
        total_success = True
        
        for checker in self.checkers:
            results = checker.run_checks()
            self.all_results.extend(results)
            
            # Check if any critical checks failed
            for result in results:
                if not result.success:
                    total_success = False
        
        self._generate_final_report()
        return total_success
    
    def _generate_final_report(self) -> None:
        """Generate final comprehensive report"""
        total_checks = len(self.all_results)
        passed_checks = sum(1 for r in self.all_results if r.success)
        
        log.info("\n" + "=" * 50)
        log.info("ç³»ç»Ÿæ£€æŸ¥å®Œæˆ")
        log.info("=" * 50)
        log.info(f"æ£€æŸ¥æ¨¡å¼: {self.mode.value.upper()}")
        log.info(f"æ€»æ£€æŸ¥é¡¹: {total_checks}")
        log.info(f"é€šè¿‡æ£€æŸ¥: {passed_checks}")
        
        if total_checks > 0:
            success_rate = (passed_checks / total_checks) * 100
            log.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        # Show timing summary
        total_duration = sum(r.duration_seconds for r in self.all_results)
        log.info(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        # Show failed checks
        failed_checks = [r for r in self.all_results if not r.success]
        if failed_checks:
            log.info("\nå¤±è´¥çš„æ£€æŸ¥:")
            for result in failed_checks:
                log.info(f"  - {result.name}: {result.message}")
        else:
            log.info("ğŸ‰ æ‰€æœ‰æ£€æŸ¥å‡é€šè¿‡ï¼ç³»ç»ŸçŠ¶æ€è‰¯å¥½ã€‚")


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="Aè‚¡é‡åŒ–æŠ•ç ”å¹³å°ç³»ç»Ÿæ£€æŸ¥")
    parser.add_argument(
        "--mode", 
        choices=["quick", "full", "stability", "performance"],
        default="full",
        help="æ£€æŸ¥æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    try:
        # Initialize data manager
        dm = data.DataManager()
        
        # Create and run orchestrator
        mode = CheckMode(args.mode)
        orchestrator = SystemCheckOrchestrator(dm, mode)
        
        success = orchestrator.run_all_checks()
        
        # Exit with appropriate code
        sys.exit(0 if success else 1)
        
    except Exception as e:
        log.error(f"ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
        log.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()