#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ€§èƒ½ç®¡ç†å™¨

é›†æˆç´¢å¼•ç®¡ç†å™¨å’ŒæŸ¥è¯¢ä¼˜åŒ–å™¨ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ¥å£
"""

import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from sqlalchemy import create_engine, text

import config
from logger_config import log
from database_index_manager import IndexManager
from database_query_optimizer import QueryOptimizer


class DatabasePerformanceManager:
    """æ•°æ®åº“æ€§èƒ½ç®¡ç†å™¨"""
    
    def __init__(self, db_url: str = None):
        self.db_url = db_url or config.DATABASE_URL
        self.engine = create_engine(self.db_url)
        self.index_manager = IndexManager(db_url)
        self.query_optimizer = QueryOptimizer(db_url)
        
    def initialize_performance_optimization(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–"""
        log.info("=== åˆå§‹åŒ–æ•°æ®åº“æ€§èƒ½ä¼˜åŒ– ===")
        
        results = {
            'index_creation': {},
            'optimization_setup': True,
            'timestamp': datetime.now().isoformat()
        }
        
        # 1. åˆ›å»ºæ ¸å¿ƒç´¢å¼•
        log.info("1. åˆ›å»ºæ ¸å¿ƒæ€§èƒ½ç´¢å¼•...")
        index_results = self.index_manager.create_all_indexes(priority_filter=1)
        results['index_creation'] = index_results
        
        success_count = sum(1 for success in index_results.values() if success)
        total_count = len(index_results)
        log.info(f"   æ ¸å¿ƒç´¢å¼•åˆ›å»º: {success_count}/{total_count} æˆåŠŸ")
        
        # 2. åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨
        log.info("2. åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨...")
        self.query_optimizer.cache.clear()  # æ¸…ç©ºç¼“å­˜é‡æ–°å¼€å§‹
        log.info("   æŸ¥è¯¢ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        
        log.info("=== æ€§èƒ½ä¼˜åŒ–åˆå§‹åŒ–å®Œæˆ ===")
        return results
    
    def execute_optimized_query(self, sql: str, params: dict = None, 
                               use_cache: bool = True) -> tuple:
        """æ‰§è¡Œä¼˜åŒ–æŸ¥è¯¢"""
        return self.query_optimizer.execute_query(sql, params, use_cache)
    
    def benchmark_performance(self) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        log.info("=== æ•°æ®åº“æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
        
        benchmark_queries = [
            {
                'name': 'å•è‚¡ç¥¨æœ€æ–°æ•°æ®',
                'sql': "SELECT * FROM ts_daily WHERE ts_code = '600519.SH' ORDER BY trade_date DESC LIMIT 1",
                'target_ms': 50,
                'category': 'stock_lookup'
            },
            {
                'name': 'å¸‚åœºæ¶¨å¹…æ’è¡Œ',
                'sql': """
                    SELECT ts_code, close, pct_chg, vol
                    FROM ts_daily 
                    WHERE trade_date = (SELECT MAX(trade_date) FROM ts_daily)
                    ORDER BY pct_chg DESC 
                    LIMIT 50
                """,
                'target_ms': 200,
                'category': 'market_ranking'
            },
            {
                'name': 'è‚¡ç¥¨å†å²æ•°æ®',
                'sql': """
                    SELECT trade_date, close, vol, pct_chg
                    FROM ts_daily 
                    WHERE ts_code = '600519.SH' 
                    AND trade_date >= '2024-01-01'
                    ORDER BY trade_date DESC
                    LIMIT 100
                """,
                'target_ms': 100,
                'category': 'stock_history'
            },
            {
                'name': 'è¡Œä¸šè‚¡ç¥¨æŸ¥è¯¢',
                'sql': """
                    SELECT ts_code, name, industry
                    FROM stock_basic 
                    WHERE industry = 'é“¶è¡Œ'
                    ORDER BY ts_code
                """,
                'target_ms': 10,
                'category': 'industry_lookup'
            },
            {
                'name': 'å› å­æ•°æ®æŸ¥è¯¢',
                'sql': """
                    SELECT ts_code, factor_value
                    FROM factors_exposure 
                    WHERE factor_name = 'pe_ttm' 
                    ORDER BY trade_date DESC, factor_value DESC
                    LIMIT 100
                """,
                'target_ms': 50,
                'category': 'factor_lookup'
            }
        ]
        
        results = {
            'test_results': [],
            'summary': {
                'total_tests': len(benchmark_queries),
                'passed_tests': 0,
                'failed_tests': 0,
                'avg_performance_ratio': 0
            },
            'timestamp': datetime.now().isoformat()
        }
        
        performance_ratios = []
        
        for query in benchmark_queries:
            log.info(f"\næµ‹è¯•: {query['name']}")
            
            # è¿è¡ŒæŸ¥è¯¢3æ¬¡å–å¹³å‡å€¼
            times = []
            for i in range(3):
                try:
                    result, stats = self.execute_optimized_query(query['sql'])
                    times.append(stats['execution_time_ms'])
                except Exception as e:
                    log.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    break
            
            if times:
                avg_time = sum(times) / len(times)
                min_time = min(times)
                max_time = max(times)
                
                # è®¡ç®—æ€§èƒ½æ¯”ç‡ï¼ˆç›®æ ‡æ—¶é—´/å®é™…æ—¶é—´ï¼Œ>1è¡¨ç¤ºè¶…è¿‡ç›®æ ‡ï¼‰
                performance_ratio = query['target_ms'] / avg_time
                performance_ratios.append(performance_ratio)
                
                test_result = {
                    'name': query['name'],
                    'category': query['category'],
                    'avg_time_ms': avg_time,
                    'min_time_ms': min_time,
                    'max_time_ms': max_time,
                    'target_ms': query['target_ms'],
                    'performance_ratio': performance_ratio,
                    'status': 'passed' if avg_time <= query['target_ms'] else 'failed',
                    'record_count': len(result) if 'result' in locals() else 0
                }
                
                results['test_results'].append(test_result)
                
                if avg_time <= query['target_ms']:
                    results['summary']['passed_tests'] += 1
                    log.info(f"  âœ“ é€šè¿‡: {avg_time:.2f}ms (ç›®æ ‡: <{query['target_ms']}ms)")
                else:
                    results['summary']['failed_tests'] += 1
                    log.info(f"  âœ— è¶…æ—¶: {avg_time:.2f}ms (ç›®æ ‡: <{query['target_ms']}ms)")
                
                log.info(f"  è®°å½•æ•°: {len(result) if 'result' in locals() else 0}")
        
        # è®¡ç®—æ€»ä½“æ€§èƒ½
        if performance_ratios:
            results['summary']['avg_performance_ratio'] = sum(performance_ratios) / len(performance_ratios)
        
        pass_rate = results['summary']['passed_tests'] / results['summary']['total_tests'] * 100
        log.info(f"\nåŸºå‡†æµ‹è¯•å®Œæˆ: {results['summary']['passed_tests']}/{results['summary']['total_tests']} é€šè¿‡ ({pass_rate:.1f}%)")
        
        return results
    
    def comprehensive_analysis(self) -> Dict[str, Any]:
        """ç»¼åˆæ€§èƒ½åˆ†æ"""
        log.info("=== ç»¼åˆæ€§èƒ½åˆ†æ ===")
        
        analysis = {
            'index_analysis': {},
            'query_optimization': {},
            'performance_benchmark': {},
            'recommendations': [],
            'timestamp': datetime.now().isoformat()
        }
        
        # 1. ç´¢å¼•åˆ†æ
        log.info("1. åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ...")
        analysis['index_analysis'] = self.index_manager.analyze_index_usage()
        
        # 2. æŸ¥è¯¢ä¼˜åŒ–ç»Ÿè®¡
        log.info("2. åˆ†ææŸ¥è¯¢ä¼˜åŒ–æƒ…å†µ...")
        analysis['query_optimization'] = self.query_optimizer.get_optimization_stats()
        
        # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
        log.info("3. æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        analysis['performance_benchmark'] = self.benchmark_performance()
        
        # 4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        log.info("4. ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        recommendations = []
        
        # åŸºäºç´¢å¼•åˆ†æçš„å»ºè®®
        if analysis['index_analysis'].get('summary', {}).get('usage_rate', '0%') < '50%':
            recommendations.append({
                'type': 'ç´¢å¼•ä¼˜åŒ–',
                'priority': 'high',
                'description': 'ç´¢å¼•ä½¿ç”¨ç‡è¾ƒä½ï¼Œå»ºè®®æ¸…ç†æœªä½¿ç”¨çš„ç´¢å¼•',
                'action': 'è¿è¡Œç´¢å¼•æ¸…ç†å·¥å…·'
            })
        
        # åŸºäºæ€§èƒ½æµ‹è¯•çš„å»ºè®®
        failed_tests = analysis['performance_benchmark']['summary']['failed_tests']
        if failed_tests > 0:
            recommendations.append({
                'type': 'æŸ¥è¯¢æ€§èƒ½',
                'priority': 'high',
                'description': f'{failed_tests}ä¸ªæŸ¥è¯¢æœªè¾¾åˆ°æ€§èƒ½ç›®æ ‡',
                'action': 'æ£€æŸ¥æ…¢æŸ¥è¯¢å¹¶ä¼˜åŒ–ç´¢å¼•ç­–ç•¥'
            })
        
        # åŸºäºç¼“å­˜çš„å»ºè®®
        cache_hit_rate = float(analysis['query_optimization']['cache_hit_rate'].rstrip('%'))
        if cache_hit_rate < 30:
            recommendations.append({
                'type': 'ç¼“å­˜ä¼˜åŒ–',
                'priority': 'medium',
                'description': f'ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½({cache_hit_rate:.1f}%)',
                'action': 'è°ƒæ•´ç¼“å­˜ç­–ç•¥å’ŒTTLè®¾ç½®'
            })
        
        analysis['recommendations'] = recommendations
        
        log.info("=== ç»¼åˆæ€§èƒ½åˆ†æå®Œæˆ ===")
        return analysis
    
    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        analysis = self.comprehensive_analysis()
        
        report_lines = [
            "=== æ•°æ®åº“æ€§èƒ½ç»¼åˆæŠ¥å‘Š ===",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "ğŸ“Š ç´¢å¼•ä½¿ç”¨æƒ…å†µ:",
            f"  æ€»ç´¢å¼•æ•°: {analysis['index_analysis']['summary']['total_indexes']}",
            f"  ä½¿ç”¨ç‡: {analysis['index_analysis']['summary']['usage_rate']}",
            f"  æ€»å¤§å°: {analysis['index_analysis']['summary']['total_size_mb']} MB",
            "",
            "ğŸš€ æŸ¥è¯¢ä¼˜åŒ–ç»Ÿè®¡:",
            f"  æ€»æŸ¥è¯¢æ•°: {analysis['query_optimization']['query_stats']['total_queries']}",
            f"  ç¼“å­˜å‘½ä¸­ç‡: {analysis['query_optimization']['cache_hit_rate']}",
            f"  ä¼˜åŒ–åº”ç”¨æ¬¡æ•°: {analysis['query_optimization']['query_stats']['optimizations_applied']}",
            "",
            "âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•:",
            f"  æµ‹è¯•é€šè¿‡ç‡: {analysis['performance_benchmark']['summary']['passed_tests']}/{analysis['performance_benchmark']['summary']['total_tests']}",
            f"  å¹³å‡æ€§èƒ½æ¯”ç‡: {analysis['performance_benchmark']['summary']['avg_performance_ratio']:.2f}",
            ""
        ]
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        report_lines.append("è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test in analysis['performance_benchmark']['test_results']:
            status_icon = "âœ“" if test['status'] == 'passed' else "âœ—"
            report_lines.append(f"  {status_icon} {test['name']}: {test['avg_time_ms']:.2f}ms (ç›®æ ‡: {test['target_ms']}ms)")
        
        report_lines.append("")
        
        # ä¼˜åŒ–å»ºè®®
        if analysis['recommendations']:
            report_lines.append("ğŸ”§ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(analysis['recommendations'], 1):
                priority_icon = "ğŸ”´" if rec['priority'] == 'high' else "ğŸŸ¡" if rec['priority'] == 'medium' else "ğŸŸ¢"
                report_lines.append(f"  {i}. {priority_icon} {rec['type']}: {rec['description']}")
                report_lines.append(f"     å»ºè®®æ“ä½œ: {rec['action']}")
                report_lines.append("")
        else:
            report_lines.append("âœ… ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®")
        
        return "\n".join(report_lines)
    
    def quick_optimize(self) -> Dict[str, Any]:
        """å¿«é€Ÿä¼˜åŒ–"""
        log.info("=== æ‰§è¡Œå¿«é€Ÿä¼˜åŒ– ===")
        
        results = {
            'actions_taken': [],
            'improvements': {},
            'timestamp': datetime.now().isoformat()
        }
        
        # 1. åˆ›å»ºç¼ºå¤±çš„é«˜ä¼˜å…ˆçº§ç´¢å¼•
        log.info("1. æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„å…³é”®ç´¢å¼•...")
        index_results = self.index_manager.create_all_indexes(priority_filter=1)
        created_indexes = [name for name, success in index_results.items() if success]
        if created_indexes:
            results['actions_taken'].append(f"åˆ›å»ºäº† {len(created_indexes)} ä¸ªå…³é”®ç´¢å¼•")
        
        # 2. æ¸…ç†ç¼“å­˜
        log.info("2. æ¸…ç†æŸ¥è¯¢ç¼“å­˜...")
        self.query_optimizer.cache.clear()
        results['actions_taken'].append("æ¸…ç†äº†æŸ¥è¯¢ç¼“å­˜")
        
        # 3. æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯
        log.info("3. æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯...")
        try:
            with self.engine.connect() as conn:
                tables = ['ts_daily', 'factors_exposure', 'financial_indicators', 'stock_basic']
                for table in tables:
                    conn.execute(text(f"ANALYZE {table}"))
                results['actions_taken'].append("æ›´æ–°äº†è¡¨ç»Ÿè®¡ä¿¡æ¯")
        except Exception as e:
            log.warning(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        
        log.info("=== å¿«é€Ÿä¼˜åŒ–å®Œæˆ ===")
        return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®åº“æ€§èƒ½ç®¡ç†å™¨")
    parser.add_argument("--init", action="store_true", help="åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–")
    parser.add_argument("--benchmark", action="store_true", help="è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
    parser.add_argument("--analyze", action="store_true", help="ç»¼åˆæ€§èƒ½åˆ†æ")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š")
    parser.add_argument("--quick-optimize", action="store_true", help="æ‰§è¡Œå¿«é€Ÿä¼˜åŒ–")
    
    args = parser.parse_args()
    
    manager = DatabasePerformanceManager()
    
    try:
        if args.init:
            result = manager.initialize_performance_optimization()
            print(f"åˆå§‹åŒ–ç»“æœ: {result}")
        
        elif args.benchmark:
            result = manager.benchmark_performance()
            print(f"åŸºå‡†æµ‹è¯•ç»“æœ: {result['summary']}")
        
        elif args.analyze:
            result = manager.comprehensive_analysis()
            print(f"åˆ†æå®Œæˆï¼Œå‘ç° {len(result['recommendations'])} ä¸ªä¼˜åŒ–å»ºè®®")
        
        elif args.report:
            report = manager.generate_performance_report()
            print(report)
        
        elif args.quick_optimize:
            result = manager.quick_optimize()
            print(f"å¿«é€Ÿä¼˜åŒ–å®Œæˆ: {result}")
        
        else:
            parser.print_help()
    
    except Exception as e:
        log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())